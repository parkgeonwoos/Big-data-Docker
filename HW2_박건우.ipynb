{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "URRWVQCuZnCs"
   },
   "source": [
    "# Spark Basics\n",
    "\n",
    "이번 notebook에서는 앞으로 학습할 Spark의 활용에 대해서 예습하고 실습해보도록 하겠습니다. \n",
    "특히 이번 실습에서는 스파크에서 중요한 역할을 하는 두가지 오브젝트 (object)에 대해서 학습합니다.\n",
    "물론 강의를 통해서 더욱 자세한 설명을 하지만, 미리 실습해보고 어떤 object인지 개념을 스스로 공부해 보겠습니다.\n",
    "\n",
    "* The Spark Context\n",
    "* The Resilient Distributed DataSet or RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A40zQY0iZnCt"
   },
   "source": [
    "### Spark Context\n",
    "* Spark는 강의 시간에 소개한 것과 같이 클러스터에서 computation abstraction을 수행해주는 소프트웨어입니다. \n",
    "* Python으로 활용하기 위한 interface를 **pyspark** 라고 합니다.\n",
    "* **SparkContext** 는 python class로 spark와 사용자 프로그램간의 연동을 책임지는 pyspark의 일부분입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QuvuCndvZnCu"
   },
   "source": [
    "<h3>Spark context 와 RDD 개요</h3>\n",
    "\n",
    "spark context와 RDD의 정확한 원리를 파악하는 것 보다 기본적 개념을 습득하는 과정입니다. 아래 그림을 통해서 간단하게 설명합니다:\n",
    "\n",
    "* 아래 그림에서는 3개의 worker node가 존재하며 우리는 spark context를 생성하여, spark context를 통해서 분산된 자원 (코어, 저장소등)을 관리합니다\n",
    "* 여기서 어떻게 자원이 관리되는지 (어떻게 데이터가 분산 저장되는지)는 spark context에서 알아서 진행하며, 프로그래밍을 하는 사용자 입장에서는 선언만 해주면 됩니다.\n",
    "* 우리가 활용하는 데이터는 spark에서 RDD라는 포맷으로 관리됩니다\n",
    "* 예를 들어서 python에서 리스트를 생성해서 RDD로 변환해주면, spark context가 알아서 RDD를 분산 저장합니다.\n",
    "* 이번 실습에서는 간단하게 RDD (or Resilient Distributed DataSet)는 spark에서 사용하는 데이터 구조로, 다중 클러스터에 저장되는 리스트라고 생각하면 될 것 같습니다.\n",
    "\n",
    "\n",
    "\n",
    "<p><img alt=\"\" src=\"https://drive.google.com/uc?id=1mzvJwWSQ5VOC9GZIJdiwFTMd0MWrK2mn\" style=\"height:324px; width:900px\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Vw85ZbzZnCu"
   },
   "source": [
    "설명한 것과 같이 cluster 환경에서 데이터 처리를 대신 맡아줄 spark context를 만들어야합니다. \n",
    "Python 환경에서 spark를 사용하기 위해서 꼭 필요한 단계로 생각하면 될 것 같습니다 (초기화).\n",
    "아래 예제 코드를 실행해 봅니다 (아래 cell을 '클릭' 하면 녹색으로 선택되며, 그 상태에서 shift+enter를 치면 해당 셀이 실행됩니다).\n",
    "We start by creating a **SparkContext** object named **sc**. In this case we create a spark context that uses 3 *executors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5430,
     "status": "ok",
     "timestamp": 1567771128746,
     "user": {
      "displayName": "Sung Hoon Lim",
      "photoUrl": "",
      "userId": "11994082970032634657"
     },
     "user_tz": -540
    },
    "id": "T7TevxJuZnCv",
    "outputId": "77b1e07f-2c8a-4291-ada2-4609a90c00b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://74346e6e7405:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[3]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[3] appName=pyspark-shell>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pyspark library에서 sparkcontext를 import합니다. (import가 무엇을 하는것인지 모르면 검색을 통해서 알아보면 좋을 것 같습니다)\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "# SparkContext를 생성하는 명령어\n",
    "sc = SparkContext(master=\"local[3]\")\n",
    "\n",
    "# 여기서 master='local[3]'라는 옵션은, 우리가 실제 클러스터 환경에서 실행하는 것이 아니기 때문에 \n",
    "# local환경에서 '3' 개의 코어를 활용하여 분산 연산을 한다고 선언하는 것입니다.\n",
    "# 해당 PC의 코어 수가 몇개인지 알아내는 방법은 역시 검색해보죠~\n",
    "\n",
    "# sc 를 출력시킵니다 (jupyter notebook에서는 셀의 마지막 줄에 표기한 값을 출력합니다, 역시 jupyter 죠)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "74O3iDqsZnCy"
   },
   "source": [
    "### 주의!!! 한번에 한개의 sparkcontext 만 생성할 수 있습니다!!\n",
    "Spark는 기본적으로 한개의 master node로 구성되기 때문에, 일반적으로 (특히 local pc 한대에서 동작하는 우리 입장에서는) 한번에 한개의 spark context만 생성할 수 있습니다. 예를 들어서 위 셀을 다시 실행해보면, 이번에는 에러가 날 것입니다. 이미 sc라는 spark context가 생성되었는데, 다시 생성하라고 명령해서 생기는 에러입니다.\n",
    "\n",
    "새로 spark context를 생성하기 위해서는 우선 실행된 spark context (sc)를 정지시켜야합니다. 이때 명령어는 \n",
    "stop( ) method로 아래 셀에 형태로 실행을 합니다. \n",
    "실수로 앞에 실행한 sc를 정지하지 않기 위해서 아래 셀은 주석처리 되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AgMRYwPuZnCy"
   },
   "outputs": [],
   "source": [
    "# sc.stop() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ws_x24PZnC0"
   },
   "source": [
    "### RDD 생성\n",
    "위에서 얘기한 것 처럼, 생성한 `RDD`는 **worker nodes**에 분산 저장됩니다. \n",
    "이 notebook은 **Master node** 한개에서만 실행되기 때문에 실제 데이터가 있지만, 항상 spark는 클러스터를 위한 체계라는 것을 생각해주세요. 즉 RDD를 master node에 생성 명령한다는 행위는 RDD가 분산 저장된다는 의미이며, 이는 더이상 master node에 이 데이터가 '실제' 저장 되지 않았다는 의미입니다. 실제로는, 분산 저장된 RDD에 대한 주소정보만 갖고 있게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-c-9IZ6DZnC1"
   },
   "source": [
    "#### Parallelize \n",
    "* RDD를 생성하는 가장 간단한 방법\n",
    "* 아래 예제코드에서는 `A=sc.parallelize(L)`라는 명령을 통해서, list `L`로 부터 `A`라는 이름의 RDD를 생성하는 과정입니다\n",
    "* 아래 셀을 실행해 봅니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1567771170889,
     "user": {
      "displayName": "Sung Hoon Lim",
      "photoUrl": "",
      "userId": "11994082970032634657"
     },
     "user_tz": -540
    },
    "id": "XVdKeKl6ZnC2",
    "outputId": "af8ef2d8-f7e5-457c-bee9-7f1af84d697e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=sc.parallelize(range(3))\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUCpAKtLZnC3"
   },
   "source": [
    "#### Collect\n",
    "\n",
    "* RDD 여러개의 excutor들 사이에 분산되어 있습니다\n",
    "* `collect()` 라는 method는 `parallelize()'의 역을(inverse) 수행합니다\n",
    "* 즉, RDD의 모든 element들을 master node로 수거하여 list를 return하는 method 입니다\n",
    "* Collect()와 같이 RDD를 다시 master node로 불러와서 실제 값을 확인할 수 있는 method, 함수를 spark에서는 action 이라고 합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1749,
     "status": "ok",
     "timestamp": 1567771175085,
     "user": {
      "displayName": "Sung Hoon Lim",
      "photoUrl": "",
      "userId": "11994082970032634657"
     },
     "user_tz": -540
    },
    "id": "7PHf3Mf3ZnC4",
    "outputId": "057b177b-2763-4952-c3eb-cf46bd6509e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "L=A.collect()\n",
    "print(type(L))\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "511Pj0B8ZnC6"
   },
   "source": [
    "###  `.collect()` 를 사용하면, 병렬 연산에 대한 기회를 소멸시킵니다\n",
    "\n",
    "프로그래밍을 하다보면, 중간 계산 값을 확인하고싶은 경우가 많이 있을 것입니다. 디버깅 과정에서는 더욱 필요한 과정이겠지만, 최종 프로그램에서는 `.collect()`를 사용하여 RDD를 master node로 불러오는 것은 분산 연산을 포기하는 것과 같습니다 (collect된 데이터는 master node에서만 연산되기 때문에). \n",
    "\n",
    "즉 연산을 RDD에 직접 구현하는 것이 필요하며, 이런 RDD에 연산을 하여 다시 다른 RDD로 변환하는 것을 transformation이라고 합니다. 다음 셀에서는 transformation 중에서 가장 기본이 되는 map 함수에 대해서 학습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZJu2nOvUZnC7"
   },
   "source": [
    "### Map\n",
    "* spark의 map은 python의 map 함수와 결과와 목적은 거의 같습니다\n",
    "* 즉, python에서 map 함수가 \n",
    "* 하지만 내부 동작은 전혀 다르며, 이는 수업시간에 배우도록 하겠습니다\n",
    "* 본 학습에서는 python map 함수와 같다고 생각하면 되며, map 함수는 수행하고자하는 operation 함수를 인자로 받습니다\n",
    "* 리턴하는 값은 RDD의 값에 map안에 정의한 operation을 각각 수행한 결과를 저장하는 RDD를 리턴합니다\n",
    "* 여기서 중요한것은 `.map()` 자체는 RDD를 리턴 한다는것입니다!!!! \n",
    "* 즉 map()은 transformation이며, master node에 저장되지 않기 때문에 리턴값을 그대로 볼 수는 없죠\n",
    "* collect()를 통해서 리턴된 값을 확인할 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yV5U02xmZnC7"
   },
   "source": [
    "**Note:** RDD return 예, List return 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 919,
     "status": "ok",
     "timestamp": 1567771176541,
     "user": {
      "displayName": "Sung Hoon Lim",
      "photoUrl": "",
      "userId": "11994082970032634657"
     },
     "user_tz": -540
    },
    "id": "4xke8gdiZnC8",
    "outputId": "4a2ac231-3ab2-4a46-e6e3-7a9f81131df7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[2] at RDD at PythonRDD.scala:53\n",
      "[0, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "# RDD\n",
    "print(A.map(lambda x: x*x))\n",
    "# List\n",
    "print(A.map(lambda x: x*x).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "36QPJZubZnC-"
   },
   "source": [
    "### Using regular functions instead of lambda functions\n",
    "\n",
    "* lambda 함수를 활용하면 편한경우가 많지만, 한 줄로 표현이 어려운 경우가 있습니다\n",
    "* 다음과 같이 일반 함수를 정의해서 사용할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 611,
     "status": "ok",
     "timestamp": 1567771178190,
     "user": {
      "displayName": "Sung Hoon Lim",
      "photoUrl": "",
      "userId": "11994082970032634657"
     },
     "user_tz": -540
    },
    "id": "9pJ5FoWCZnC-",
    "outputId": "7220bd4e-bcb2-4e32-d950-1ccd886993f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square(x):\n",
    "    return x**2\n",
    "\n",
    "A.map(square).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "InKoJN3cZnDB",
    "nbgrader": {
     "grade": false,
     "grade_id": "Excercise1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Excercise 1\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "1. `mapcos`이라는 다음 함수를 만들어보세요: \n",
    "  * input: 수(number)로 이루어진 RDD\n",
    "  * RDD 각 element에 `cos()` (cosine)을 계산해서 list를 리턴\n",
    "\n",
    "다음 값을 출력하는지 확인하세요\n",
    "    \n",
    "```\n",
    "    [1.0, 0.54030..., -0.41614...]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3JIDia3XMHBJ",
    "nbgrader": {
     "grade": false,
     "grade_id": "t1",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.5403023058681398, -0.4161468365471424]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# numpy에서 cosine 함수가 무엇인지 검색해보세요\n",
    "\n",
    "def mapcos(A):#mapcos함수를 만듦\n",
    "    return A.map(np.cos).collect()#map함수를 사용해서 결과갑을 RDD로 리턴해주면 안에 있는np.cos은 numpy의 코사인 함수를 사용한단 것이며\n",
    "#collcect를 통해서 값을 반환해 주는 것임.\n",
    "\n",
    "    \n",
    "  \n",
    "  \n",
    "\n",
    "# 답 확인\n",
    "mapcos(A)#함수 사용하여 결과값을 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJpUiHXVZnDD"
   },
   "source": [
    "### Excercise 2\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "다음 RDD에 대하여 다음 과제를 수행하세요: \n",
    "\n",
    "```\n",
    "stringRDD=sc.parallelize([\"Fall semester\", \"Learning spark basics\", \"Big data analytics with Spark\"])\n",
    "```\n",
    "   `mapwords`라는 함수를 작성\n",
    "   * input: RDD of strings \n",
    "   * output: returns a list of words for each string\n",
    "   \n",
    "```mapwords(stringRDD)``` 가 다음을 출력하도록 합니다:\n",
    "    \n",
    "``` \n",
    "[['Fall', 'semester'], ['Learning', 'spark', 'basics'], ['Big', 'data', 'analytics', 'with', 'Spark']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktTvmRQ7ZnDE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fall semester', 'Learning spark basics', 'Big data analytics with Spark']\n"
     ]
    }
   ],
   "source": [
    "# Excercise 2 답 작성\n",
    "stringRDD=sc.parallelize([\"Fall semester\", \"Learning spark basics\", \"Big data analytics with Spark\"])# rdd를 생성하고  LIST를 만듦\n",
    "\n",
    "def mapword(rdd_temp):#MAPWORD함수를 만듦,인자는 리스트를 받음\n",
    "    return rdd_temp.collect()#COLLECT함수로 인자를 반환\n",
    "  \n",
    "  # 여기에 코드를 입력하세요.\n",
    "    \n",
    "\n",
    "print(mapword(stringRDD))#문자열 형태로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1cGStHabZnDF"
   },
   "source": [
    "### Reduce\n",
    "\n",
    "* Reduce는 map과 마찬가지로, python reduce 함수와 같은 기능을 합니다\n",
    "* python reduce에 대해서 검색해보고 복습해보세요\n",
    "* 사용 방식은 input으로 function **두개** 의 element를 받는 function을 받으며 **한개**의 output을 리턴합니다\n",
    "* Reduce는 action 입니다, 즉 `reduce()` 를 실행하면 master node로 값을 실제 리턴합니다\n",
    "* 마찬가지로 내부적으로는 python reduce와는 다르게 동작하며, 이는 강의를 통해서 배우도록 하겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "20RQewp9ZnDG"
   },
   "source": [
    "가장 간단한 2대1 operation인 합을 구합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1567771190131,
     "user": {
      "displayName": "Sung Hoon Lim",
      "photoUrl": "",
      "userId": "11994082970032634657"
     },
     "user_tz": -540
    },
    "id": "xTDVULDJZnDG",
    "outputId": "db395738-e574-4158-b7de-63368ec9ce2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRi9VNcGZnDI"
   },
   "source": [
    "물론 action이기 때문에 따로 collect는 필요 없이 실제 계산 값이 출력되었을 것입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i6qnRPF5ZnDI"
   },
   "source": [
    "아래 예제는 string list를 RDD로 변환하여 가장 짧은 단어를 찾는 예제입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1567771192132,
     "user": {
      "displayName": "Sung Hoon Lim",
      "photoUrl": "",
      "userId": "11994082970032634657"
     },
     "user_tz": -540
    },
    "id": "HiU1vNvPZnDJ",
    "outputId": "9aa08250-3241-46ee-eaeb-04e0eafc324f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=['this','is','the','best','computer','ever']\n",
    "wordRDD=sc.parallelize(words)\n",
    "wordRDD.reduce(lambda w,v: w if len(w)<len(v) else v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ytmByOaQZnDK"
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "1. `reduce` command를 활용하여 ```RDD=sc.parallelize([0,2,1])``` RDD에서 가장 큰수를 출력하도록 작성하세요\n",
    "\n",
    "   Output: ``` 2 ```\n",
    "   \n",
    "\n",
    "2. 위 Exercise 2에서 정의한 stringRDD를 `reduce` command 를 활용하여 다음과 같이 하나의 string으로 출력되도록 하세요:\n",
    "\n",
    "    Output: ``` 'Fall semester Learning spark basics Big data analytics with Spark' ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzfqvZ2vZnDL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computer'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 3-1 답 작성\n",
    "words=['this','is','the','best','computer','ever'] #리스트 만듦\n",
    "wordRDD=sc.parallelize(words)#RDD를 생성하고 word를 인자로 받음\n",
    "wordRDD.reduce(lambda w,v: w if len(w)>len(v) else v)#lambda를 통해서 길이 비교 식을 만들고 그 함수를 실행시켜줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8f_cPdVcZnDN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fall semesterLearning spark basicsBig data analytics with Spark'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=([\"Fall semester\", \"Learning spark basics\", \"Big data analytics with Spark\"])#리스트 만듦\n",
    "wordRDD=sc.parallelize(words)#RDD를 생성하고 인자를 받음\n",
    "wordRDD.reduce(lambda w,v:w+v)#w+v를 람다를 통해 실행\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOPzzaB3ZnDO"
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "위 예제에서 작성한 wordRDD에 reduce operation을 취해서 다음 결과가 출력되도록 아래 largerThan 함수를 완성하세요\n",
    "suppose we want to find the \n",
    "\n",
    "* 가장 긴 단어들 중에서 (길이가 같은 단어 존재)\n",
    "* lexiographic (a,b,c, 순) 순서가 가장 뒤인 단어를 출력하세요\n",
    "\n",
    "   Output: ``` 'computer' ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZuVeSeNvZnDP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computer'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 4 답 작성\n",
    "words=['this','is','the','best','computer','ever']#리스트를 만듦\n",
    "def largerThan(x,y):#함수 largerThan을 생성\n",
    "    \n",
    "    if len(x)>len(y):#함수x길이가 y보다 길다면\n",
    "        return x #x값을 반환\n",
    "    else:\n",
    "        return y#y값을 반환\n",
    "    \n",
    "    # 여기에 코드 작성 \n",
    "\n",
    "\n",
    "# 결과출력 \n",
    "wordRDD.reduce(largerThan) #reduce함수를 통해서 함수largerThan를 실행함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w7PxNxwWZnDR"
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "1. 다음 RDD에 대해서 아래 과정을 수행하세요:\n",
    "\n",
    "    ``` listRDD=sc.parallelize([[3,4],[2,1],[7,9]]) ```\n",
    " \n",
    "     `reduce` command 를 활용하여 리스트안에 수들 중에서 가장 큰 수를 출력하도록 함수를 완성하세요. 출력값은 다음과 같아야 합니다:\n",
    "     \n",
    "     Output: ```[9]```\n",
    "     \n",
    "     (Note: 출력값이 하나의 수가 아닌 1개 element의 리스트입니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qbcba-3XZnDR",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5 답안 작성\n",
    "listRDD=sc.parallelize([[3,4],[2,1],[7,9]])#리스트를 생성\n",
    "#리스트 합쳐서 그 중에 하나 뽑아서 하기.\n",
    "def LeastNumber(x,y):#함수 LeastNumber를 만들고 x,y인자를 받음 인자는 리스트를 받을 예정\n",
    "    a=x+y #a가 리스트를 합침\n",
    "    b=[max(a)] #b는 합친 리스트의 최댓값을 나타냄 \n",
    "    return b#b값을 반환함\n",
    "    \n",
    "    \n",
    "  \n",
    "\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "  # 여기에 코드 작성\n",
    "    \n",
    "listRDD.reduce(LeastNumber)#reduce 함수를 통해서 LeasNumber를 실행\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lLYG2aCQgIxE"
   },
   "source": [
    "### **Exercise 6**\n",
    "\n",
    "- - - -\n",
    "1. `reduce` command를 활용하여 입력받은 수(6개 이상, 10<=N<=20) N의 팩토리얼을 구하는 식을 작성하세요.\n",
    "    \n",
    "    **단, 입력받은 수만큼의 RDD를 생성하세요(6개 이상)**\n",
    "    \n",
    "   ex)\n",
    "   \n",
    "   ```Input ``` : 10 11 13 16 18 20\n",
    "   \n",
    "   ```output :  ```\n",
    "   \n",
    "   10 의 factorial :  3628800\n",
    "   \n",
    "   11 의 factorial :  39916800\n",
    "   \n",
    "   13 의 factorial :  6227020800\n",
    "   \n",
    "   16 의 factorial :  20922789888000\n",
    "   \n",
    "   18 의 factorial :  6402373705728000\n",
    "   \n",
    "   20 의 factorial :  2432902008176640000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5aGxWWj9gIxG",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "13\n",
      "16\n",
      "18\n",
      "20\n",
      "0\n",
      "10 의 factorial :  3628800 \n",
      "\n",
      "11 의 factorial :  39916800 \n",
      "\n",
      "13 의 factorial :  6227020800 \n",
      "\n",
      "16 의 factorial :  20922789888000 \n",
      "\n",
      "18 의 factorial :  6402373705728000 \n",
      "\n",
      "20 의 factorial :  2432902008176640000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc.stop()\n",
    "sc = SparkContext(master=\"local[*]\")\n",
    "\n",
    "temp=[]#내가 입력할 수들의 리스트를 저장하기 위한 빈 리스트 생성\n",
    "\n",
    "while True:\n",
    "    a=(int(input()))#내가 값을 입력할 수 있도록 해줌\n",
    "    if a==0: \n",
    "        break\n",
    "    temp.append(a)\n",
    "    \n",
    "RDD_list = []#리스트를 RDD값으로 변환하여 저장해줄 공백 리스트 선언\n",
    "for i in range(len(temp)):\n",
    "    RDD_list.append(sc.parallelize(range(1,temp[i]+1)))#반복문으로 리스트의 저장 된 값을을 하나하나 RDD로 만들어 RDD_list에 저장한다\n",
    "for i in range(len(RDD_list)):\n",
    "    print(temp[i],'의 factorial : ',RDD_list[i].reduce(lambda x,y: x*y),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2432902008176640000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def factorial_reduce(n):\n",
    "    return reduce(lambda x, y: x * y, range(1, n+1))\n",
    "\n",
    "\n",
    "factorial_reduce(20)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdUQX-7w3eF2"
   },
   "source": [
    "### **Exercise 7**\n",
    "\n",
    "- - - -\n",
    "\n",
    "HW1의 과제 2번 문제를 RDD를 이용해서 해결하세요. \n",
    "\n",
    "**단, value를 직접적으로 sort 하지 말 것(발견시 0점처리) ==> value.sort() X**\n",
    "\n",
    "\n",
    "```input``` :  value = [46,960,19,182,365,929,568,627,510,355,313,82,742,656,385,181,827,197,809,413] \n",
    "\n",
    "```output``` :\n",
    "\n",
    "              minimum sum =  8206\n",
    "              maximum sum =  9147 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QV67PWQF3eF3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum sum =  8206\n",
      "maximum sum =  9147\n"
     ]
    }
   ],
   "source": [
    "sc.stop()\n",
    "sc = SparkContext(master=\"local[*]\")\n",
    "value = [46,960,19,182,365,929,568,627,510,355,313,82,742,656,385,181,827,197,809,413]#값의 리트스를 만듦\n",
    "\n",
    "List_RDD=sc.parallelize(value)#RDD를 만들고 인자값으로 VALUE를 넣음\n",
    "\n",
    "min=sum(List_RDD.sortBy(lambda x : x).collect()[:19])#리스트 19를 제외하고 반복하여 정렬 (슬라이싱)\n",
    "\n",
    "max=sum(List_RDD.sortBy(lambda x : x).collect()[1:])#리스트1을 제외하고 끝까지 반복하여 정렬(슬라이싱)\n",
    "\n",
    "print('minimum sum = ',min)#프린트문으로 가장 적은 값을 더해서 나타내줌\n",
    "print('maximum sum = ',max)#프린트문으로 가장 큰 값을 더해서 나타내줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4ZkRL_QKZQc"
   },
   "source": [
    "### **Exercise 8**\n",
    "#### python의 reduce와 spark의 reduce의 수행시간 비교.\n",
    "\n",
    "- - - -\n",
    "\n",
    "```동일한 변수```를 통해서 결과를 도출한 수행시간을 비교한 예제입니다.\n",
    "\n",
    "```%%time```을 통해 수행시간을 비교한 결과 ```python의 reduce```가 더 빠르게 작동하는 것을 확인할 수 있습니다.\n",
    "\n",
    "**이유는 무엇일까요?(아직 배우지는 않았지만 추측을 통해서 2 ~ 4 문장 이내로 서술할 것)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-fS8po1KZQd"
   },
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "sc = SparkContext(master=\"local[*]\")\n",
    "\n",
    "value = np.ones(10**5, dtype = 'i').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CayBoQfGKZQf",
    "outputId": "430ce125-75fe-499e-d546-6ae748a9faef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===============pyspark reduce=================\n",
      "pyspark reduce all sum :  100000\n",
      "CPU times: user 40 ms, sys: 0 ns, total: 40 ms\n",
      "Wall time: 651 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"\\n ===============pyspark reduce=================\")\n",
    "RDD = sc.parallelize(value)\n",
    "print(\"pyspark reduce all sum : \", RDD.reduce(lambda x, y : x + y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b6nRBsk3KZQi",
    "outputId": "5201c9fa-23cf-470b-b589-127263842504",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===============python reduce=================\n",
      "python reduce all sum :  100000\n",
      "CPU times: user 20 ms, sys: 0 ns, total: 20 ms\n",
      "Wall time: 25.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from functools import reduce\n",
    "print(\"\\n ===============python reduce=================\")\n",
    "print(\"python reduce all sum : \", reduce(lambda x, y : x + y, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9njdDeJBAUMz"
   },
   "source": [
    "#### Exercise 8 답안 작성\n",
    "\n",
    ": 여기에 작성하세요..! (2 ~ 4문장으로 서술할 것.)\n",
    "\n",
    "reduce함수는 재귀식으로 반복으로 실행되는데 특화되어 있어서 rdd파이썬 쪽에 수행능력이 빠른 걸로 알고 있습니다.\n",
    "따라서 print문으로 실행하는 거보다 import를 해주고 쓰면 직접 바로 실행이 되므로 위에는 함수를 불러오고 실행하지만 \n",
    "아래같은 경우는 상속을 받았기 때문에 바로 실행되므로 좀 더 빠른 거 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I1GrpeMQZnDW"
   },
   "source": [
    "### 수고하셨습니다"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_HW2_upload.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
