{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kEXZMQxASNvO"
   },
   "source": [
    "# Key/Value RDD\n",
    "\n",
    "---\n",
    "\n",
    "이번 notebookt에서는 Spark의 Key/Vlaue RDD 이어서 학습합니다. \n",
    "\n",
    "Key/Vlaue RDD가 기억이 안 난다면, **HW3의 내용을 다시 복습 후에 진행하시길 권장**합니다. \n",
    "\n",
    "\n",
    "* task 별로 부분점수가 있습니다.(task 가 없는 경우는 부분점수가 없습니다(Exercise 1,2))\n",
    "\n",
    "* 과제 제출기간 : 10월 1일 실습시간부터 ~ 10월 7월 오후 23:59분까지(+7일)\n",
    "\n",
    " - - -\n",
    " \n",
    "**과제 점수 부여방식**\n",
    "\n",
    " * 데드라인(실습시간으로부터 +7일) 이후 제출시, +8 ~ +10일 까지는 해당 과제 점수의 20% 차감, +11일부터는 0점\n",
    " * 데드라인 이후 제출시, sempre813@naver.com로 학번_이름을 포함하여 보내주세요. (메일 보낸시간 == 제출 시간)\n",
    " * Exercise 수행시 주석이 없을 경우, 해당 Exercise 0점\n",
    " * copy and paste 발견시 예외없이 해당 주차 과제 0점(보여준 사람 포함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZUY9Hj0WlkR"
   },
   "source": [
    "### pyspark import & SparkContext 생성(이제는 무엇인지 알아야 한다..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rg3IdC0uWlkS",
    "outputId": "aa34cd41-c6f9-464c-a283-32bbfe3416dc",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-1-da55dcd4d67e>:2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-da55dcd4d67e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"local[*]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#sc.stop()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    330\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 332\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    333\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-1-da55dcd4d67e>:2 "
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(master=\"local[*]\")\n",
    "sc\n",
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xXuSUObrWlkf"
   },
   "source": [
    "## Key-Value Transformations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hCOoFzJ21dmL"
   },
   "source": [
    "(1) **keys() : key/value RDD에서 키가 있는 RDD 또는 key/value RDD 각 튜플의 첫 번째 요소(key)를 반환.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFdbCnuj1dmM",
    "outputId": "e56bf766-40e1-4ff6-f9e1-31d984b59b4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city', 'state', 'zip', 'country']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kvpairs = sc.parallelize([('city', 'Hayward'), ('state', 'CA'), ('zip', 94541), ('country', 'USA')])\n",
    "\n",
    "kvpairs.keys().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CRUqnc4U1dmP"
   },
   "source": [
    "(2) **values() : key/value RDD에서 키가 있는 RDD 또는 key/value RDD 각 튜플의 두 번째 요소(value)를 반환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGHU0SzY1dmQ",
    "outputId": "cdf0bff2-1a30-41d4-f59f-32ebb425c407"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hayward', 'CA', 94541, 'USA']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kvpairs = sc.parallelize([('city', 'Hayward'), ('state', 'CA'), ('zip', 94541), ('country', 'USA')])\n",
    "\n",
    "kvpairs.values().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UeLyI-371dmS"
   },
   "source": [
    "(3) **keyBy(function) : function 인수로 지정된 함수를 적용해 RDD에 있는 요소의 key와 value로 구성된 튜플을 만든다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-Ja7R5n1dmT",
    "outputId": "0362ee52-36d9-4cc2-b786-ea80b6deffb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, ('Hayward', 'USA', 1)),\n",
       " (2, ('Baumholder', 'Germany', 2)),\n",
       " (3, ('Alexandria', 'USA', 3)),\n",
       " (4, ('Melbourne', 'Australia', 4))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = sc.parallelize([('Hayward', 'USA', 1), ('Baumholder', 'Germany', 2), ('Alexandria', 'USA', 3), \n",
    "                           ('Melbourne', 'Australia', 4)])\n",
    "\n",
    "bylocno = locations.keyBy(lambda x: x[2])\n",
    "bylocno.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gkQmACI1dmW"
   },
   "source": [
    "## Exercise 1 (10 point)\n",
    "\n",
    "- - -\n",
    " \n",
    "다음 RDD에 대하여 다음 과제를 수행하세요.\n",
    "\n",
    "```\n",
    "sc.parallelize([('Hayward', 'USA', 1), ('Baumholder', 'Germany', 2), ('Alexandria', 'USA', 3),('Melbourne', 'Australia', 4)])\n",
    "```\n",
    "\n",
    "`keyBySelect`라는 함수를 작성\n",
    "\n",
    "- input: RDD of tuple\n",
    "- output : **국가명이 Key**, **도시명이 Value**인 key/value RDD(**tip.map 또는 mapValue를 사용**)\n",
    "\n",
    "`keyBySelect(tupleRDD)`가 다음을 출력하도록 합니다.\n",
    "\n",
    "```\n",
    "[('USA', 'Hayward'), ('Germany', 'Baumholder'), ('USA', 'Alexandria'), ('Australia', 'Melbourne')]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkjUO2wI1dmX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('USA', 'Hayward'), ('Germany', 'Baumholder'), ('USA', 'Alexandria'), ('Australia', 'Melbourne')]\n"
     ]
    }
   ],
   "source": [
    "# 여기에 코드를 입력하세요\n",
    "locations=sc.parallelize([('Hayward', 'USA', 1), ('Baumholder', 'Germany', 2), ('Alexandria', 'USA', 3),('Melbourne', 'Australia', 4)])\n",
    "#RDD를 생성\n",
    "def keyBySelect(tupleRDD):#keyBySelect함수를 생성(RDD를 인자로 받음)\n",
    "    a = tupleRDD.map(lambda x : (x[1],x[0])).collect()#a라는 인자는 RDD.map의 람다식으로 x[1],x[0]으로 지정해서 바꿔서 저장하는 RDD생성\n",
    "    return a#a의 값을 리턴함\n",
    "  \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "print(keyBySelect(locations))#keyBySelect함수를 사용하는데 RDD인자는 locations RDD를 인자로 받아서 출력함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r7iYI5XdoLIo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "572op8NOoLLt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCRqP_9F1dme"
   },
   "source": [
    "(3) **subtractByKey(RDD) : RDD1, RDD2가 주어졌을 때, RDD1에서 RDD2와 같은 key 가질 경우 해당 요소 삭제**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2yMaEfn7Wlkg",
    "outputId": "8a31ffc4-14f2-4652-fb75-0ece304e9613",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1= [(1, 2), (2, 1), (2, 2)]\n",
      "rdd2= [(2, 5), (3, 1)]\n",
      "subtractByKey_Result: [(1, 2)]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([(1,2),(2,1),(2,2)])\n",
    "rdd2 = sc.parallelize([(2,5),(3,1)])\n",
    "\n",
    "print('rdd1=',rdd1.collect())\n",
    "print('rdd2=',rdd2.collect())\n",
    "print(\"subtractByKey_Result:\", rdd1.subtractByKey(rdd2).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M0PZi7KmWlkj"
   },
   "source": [
    "### ``join``에 관련된 간단한 설명 (해석하는 것이 힘들다면.. [여기클릭](https://futurists.tistory.com/17))\n",
    "\n",
    "There are four variants of `join` which differ in how they treat keys that appear in one dataset but not the other.\n",
    "* `join` is an *inner* join which means that keys that appear only in one dataset are eliminated.\n",
    "* `leftOuterJoin` keeps all keys from the left dataset even if they don't appear in the right dataset. The result of leftOuterJoin in our example will contain the keys `John, Jill, Kate`\n",
    "* `rightOuterJoin` keeps all keys from the right dataset even if they don't appear in the left dataset. The result of leftOuterJoin in our example will contain the keys `Jill, Grace, John`\n",
    "* `FullOuterJoin` keeps all keys from both datasets. The result of leftOuterJoin in our example will contain the keys `Jill, Grace, John, Kate`\n",
    "\n",
    "In outer joins, if the element appears only in one dataset, the element in `(K,(V,W))` that does not appear in the dataset is represented bye `None`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ode4olQWlkk"
   },
   "source": [
    "(4) **(inner) join**\n",
    "\n",
    "* A fundamental operation in relational databases.\n",
    "* assumes two tables have a **key** column in common. \n",
    "* merges rows with the same key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_XT4G3LTWlkl"
   },
   "source": [
    "|**dataset 1**|                                     |..........| **dataset 2** | \t       \t     |\n",
    "|-------------|-------------------------------------|   |-------------|-----------------|\n",
    "| **key=name**   |   **(gender,occupation,age)**    |   |  **key=name**   |   **hair color**    |\n",
    "| John   |  (male,cook,21)                          |   | Jill   |  blond |\n",
    "| Jill   |  (female,programmer,19)                  |   | Grace  |  brown |         \n",
    "| John   |  (male, kid, 2)                          |   | John   |  black |\n",
    "| Kate   |  (female, wrestler, 54)                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ebWkXZycWlkm"
   },
   "source": [
    "When `Join` is called on datasets of type `(Key, V)` and `(Key, W)`, it  returns a dataset of `(Key, (V, W))` pairs with all pairs of elements for each key. Joining the 2 datasets above yields:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DKbcW3YXWlkn"
   },
   "source": [
    "\n",
    "|   key = name | (gender,occupation,age),haircolor |\n",
    "|--------------|-----------------------------------|\n",
    "| John         | ((male,cook,21),black)             |\n",
    "| John         | ((male, kid, 2),black)             |\n",
    "| Jill         | ((female,programmer,19),blond)     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mQ9UXtqqWlkn",
    "outputId": "134ebe0b-f2fe-478a-ec2d-589965f3d4bc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1= [(1, 2), (2, 1), (2, 2)]\n",
      "rdd2= [(2, 5), (3, 1)]\n",
      "Join_Result: [(2, (1, 5)), (2, (2, 5))]\n"
     ]
    }
   ],
   "source": [
    "print('rdd1=',rdd1.collect())\n",
    "print('rdd2=',rdd2.collect())\n",
    "print(\"Join_Result:\", rdd1.join(rdd2).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1JZUpOIWlkq"
   },
   "source": [
    "(5) **leftOuterJoin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJoPMIUsWlkr",
    "outputId": "e2de3735-2aa9-4995-f41b-35dcc7795704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1= [(1, 2), (2, 1), (2, 2)]\n",
      "rdd2= [(2, 5), (3, 1)]\n",
      "Result: [(1, (2, None)), (2, (1, 5)), (2, (2, 5))]\n"
     ]
    }
   ],
   "source": [
    "print('rdd1=',rdd1.collect())\n",
    "print('rdd2=',rdd2.collect())\n",
    "print(\"Result:\", rdd1.leftOuterJoin(rdd2).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDgPxVAEWlku"
   },
   "source": [
    "(6) **rightOuterJoin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bD0FJcNQWlkv",
    "outputId": "d3becaae-0071-40de-a15d-ad7caab3dba1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1= [(1, 2), (2, 1), (2, 2)]\n",
      "rdd2= [(2, 5), (3, 1)]\n",
      "Result: [(2, (1, 5)), (2, (2, 5)), (3, (None, 1))]\n"
     ]
    }
   ],
   "source": [
    "print('rdd1=',rdd1.collect())\n",
    "print('rdd2=',rdd2.collect())\n",
    "print(\"Result:\", rdd1.rightOuterJoin(rdd2).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8jxkX07rCOLg"
   },
   "source": [
    "## Exercise 2 (10 point)\n",
    "\n",
    "- - -\n",
    " \n",
    "다음 RDDs에 대하여 다음 과제를 수행하세요.\n",
    "\n",
    "```\n",
    "stores = sc.parallelize([(100, 'Boca Raton'), (101, 'Columbia'), (102, 'Cambridge'), (103, 'Naperville')])\n",
    "salespeople = sc.parallelize([(1, 'Henry', 100), (2, 'Karen', 100), (3, 'Paul', 101), (4, 'Jimmy', 102), (5, 'Janice', None)])\n",
    "```\n",
    "\n",
    "- input: stores, salepeople(RDD)\n",
    "- output : `joinResult` 결과\n",
    "\n",
    "`joinResult(RDD1, RDD2)`가 다음을 출력하도록 합니다.\n",
    "\n",
    "```\n",
    "[(100, ((1, 'Henry', 100), 'Boca Raton')), (100, ((2, 'Karen', 100), 'Boca Raton')), (101, ((3, 'Paul', 101), 'Columbia')), (102, ((4, 'Jimmy', 102), 'Cambridge'))]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-re6SDvPCOLh",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100, ((1, 'Henry', 100), 'Boca Raton')), (100, ((2, 'Karen', 100), 'Boca Raton')), (102, ((4, 'Jimmy', 102), 'Cambridge')), (101, ((3, 'Paul', 101), 'Columbia'))]\n"
     ]
    }
   ],
   "source": [
    "# 여기에 코드를 입력하세요.\n",
    "stores = sc.parallelize([(100, 'Boca Raton'), (101, 'Columbia'), (102, 'Cambridge'), (103, 'Naperville')])\n",
    "salespeople = sc.parallelize([(1, 'Henry', 100), (2, 'Karen', 100), (3, 'Paul', 101), (4, 'Jimmy', 102), (5, 'Janice', None)])\n",
    "#문제에 주어진 RDD 2개를 생성함\n",
    "def joinResult(RDD1, RDD2):#JoinResult(RDD를 두개로 인자를 받음)생성\n",
    "    a=RDD2.keyBy(lambda x : x[2])#key값을 앞으로 빼내기 위해 x[2]에 들어있기 때문에 뒤에 있는 x[2]의 값들을 key,value식으로 뺴줌\n",
    "    b = a.join(RDD1)#b는 a의 나온 key,value값에 RDD1을 합침\n",
    "    return b.collect()#b의 값을 collect함수로 추출후 반환\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "print(joinResult(stores,salespeople))#함수JoinResult에 RDD 2개를 인자로 받아주고 출력함ㄴ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a44JDPd3oJc2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rOb2R0Z1oJuJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fPGfZzgtWlkx"
   },
   "source": [
    "## Key-Value Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hd2GMXrGWlky"
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(1,2), (2,4), (2,6)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_P3W_528Wlk1"
   },
   "source": [
    "#### 1. countByKey(): \n",
    "Count the number of elements for each key. Returns a dictionary for easy access to keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvrGjW5hWlk1",
    "outputId": "e2448ef3-366f-472f-a55d-a042edf97c48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD:  [(1, 2), (2, 4), (2, 6)]\n",
      "Result: defaultdict(<class 'int'>, {1: 1, 2: 2})\n"
     ]
    }
   ],
   "source": [
    "print(\"RDD: \", rdd.collect())\n",
    "result = rdd.countByKey()\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Saw0gkeXWlk4"
   },
   "source": [
    "#### 2. collectAsMap(): \n",
    "Collect the result as a dictionary to provide easy lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69BEjrs1Wlk5",
    "outputId": "c78bad29-7909-4d25-ae99-cef613452afd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD:  [(1, 2), (2, 4), (2, 6)]\n",
      "Result: {1: 2, 2: 6}\n"
     ]
    }
   ],
   "source": [
    "print(\"RDD: \", rdd.collect())\n",
    "result = rdd.collectAsMap()\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YokG5jUwWlk7"
   },
   "source": [
    "#### 3. lookup(key): \n",
    "Return all values associated with the provided key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Vwd8xtJWlk8",
    "outputId": "55d1697d-e195-41a4-b8a8-3e4463cd6179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD:  [(1, 2), (2, 4), (2, 6)]\n",
      "Result: [4, 6]\n"
     ]
    }
   ],
   "source": [
    "print(\"RDD: \", rdd.collect())\n",
    "result = rdd.lookup(2)\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iRy6dOuiCOL5"
   },
   "source": [
    "## Exercise 3 - Key/Value RDD 종합1 (20 point)\n",
    "\n",
    "- - -\n",
    " \n",
    "다음 데이터에 대하여 다음 과제를 수행하세요.\n",
    "\n",
    "- regular.csv : KBO에서 활약한 타자들의 역대 정규시즌 성적을 포함하여 몸무게, 키 ,생년월일 등의 기본정보\n",
    "\n",
    "**위의 두 데이터는 모두 `,`로 구분되어 있습니다.**\n",
    "\n",
    " - **데이터의 자세한 설명은 다음의 링크를 참조해주세요.([여기를 눌러서 12. 데이터 설명 참고](https://dacon.io/cpt6/62885))**\n",
    " - 또한 regular.csv와 pre.csv를 직접 열어서 데이터가 어떻게 저장되어 있는지 확인해주세요.\n",
    "\n",
    "- - -\n",
    "\n",
    "**`kboplayerName(task)` :역대 정규시즌 성적에서 타율(avg)이 3할(0.300)을 8번 이상 기록했던 선수의 이름을 출력하는 함수.**\n",
    "\n",
    "- input: sc.testFile를 이용하여 regular.csv를 RDD로 생성\n",
    "- output : `kboplayerName` 결과\n",
    "\n",
    "**task**\n",
    "\n",
    "`kboplayerName(task)` 함수는 다음의 기능을 담고 있습니다.\n",
    "\n",
    "- 1. map을 사용하여 key(타자 이름)/value(타율)의 RDD로 transformation 합니다. (5 point)\n",
    "\n",
    " **단, value(tuple)의 타입은 float이 되도록 합니다. 또한, 타율 항목이 ''(공백)인 경우 0으로 처리합니다.** \n",
    " \n",
    " \n",
    "- 2. map을 사용하여, if value == '' return (key, 0) else (key, float(value)인 RDD로 transformation 합니다. (5 point)\n",
    "- 3. filter를 사용하여 value가 0.300 이상인 RDD로 transformation 합니다. (5 point)\n",
    "- 4. countByKey를 사용하여 3할을 8번 이상 기록했던 선수의 이름을 출력합니다. (5 point) \n",
    "\n",
    " [python dictionary 참고](https://junho85.pe.kr/671)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "`kboplayerName(task)`가 다음을 출력하도록 합니다.\n",
    "\n",
    "```\n",
    "['김동주', '김주찬', '김태균', '김현수', '박용택', '박한이', '손아섭', '이대호', '이진영', '이택근', '장성호', '정근우', '정성훈', '최형우']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fi2gXFROCOL_"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "\n",
    "f = urllib.request.urlretrieve (\"https://docs.google.com/uc?export=download&id=1XaYz8IPIlxsWia59RUdTJtfkLNc2MJqk\", \"pre.csv\")\n",
    "f = urllib.request.urlretrieve (\"https://docs.google.com/uc?export=download&id=1b_L-rJYJC9Oqga0fQ2zh2M763CTM8jzR\", \"regular.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KazORrSSCOME",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-cffc86504bb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkboplayerName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-cffc86504bb0>\u001b[0m in \u001b[0;36mkboplayerName\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkboplayerName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "regular = \"./regular.csv\"\n",
    "regular = sc.textFile(regular)\n",
    "\n",
    "# 여기에 코드를 입력하세요\n",
    "def kboplayerName(task):\n",
    "    for i in range(100000):\n",
    "        task.map(lambda x:x[1],x[4])\n",
    "    return task\n",
    "        \n",
    "\n",
    "print(kboplayerName(regular))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9tkJN45doEHm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zyorbVp8oEJ3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JS_Y2GcHCOMH"
   },
   "source": [
    "## Exercise 4 - Key/Value RDD 종합 2 (20 point)\n",
    "\n",
    "- - -\n",
    " \n",
    "다음 데이터에 대하여 다음 과제를 수행하세요.\n",
    "\n",
    "- regular.csv : KBO에서 활약한 타자들의 역대 정규시즌 성적을 포함하여 몸무게, 키 ,생년월일 등의 기본정보\n",
    "- pre.csv : KBO에서 활약한 타자들의 **역대 시범경기(정규시즌 직전에 여는 연습경기)** 성적\n",
    "\n",
    "**위의 두 데이터는 모두 `,`로 구분되어 있습니다.**\n",
    "\n",
    " - **데이터의 자세한 설명은 다음의 링크를 참조해주세요.([여기를 눌러서 12. 데이터 설명 참고](https://dacon.io/cpt6/62885))**\n",
    " - 또한 regular.csv와 pre.csv를 직접 열어서 데이터가 어떻게 저장되어 있는지 확인해주세요.\n",
    "\n",
    "- - -\n",
    "\n",
    "**`hitCompare(task)`** :\n",
    "\n",
    "**역대 정규시즌의 평균 타율과 역대 시범경기 평균 타율을 비교하여, 역대 정규시즌 평균 타율이 역대 시범경기 타율보다 높은 선수의 이름을 출력하는 함수**\n",
    "\n",
    "- input: sc.testFile를 이용하여 regular.csv, pre.csv를 각각 RDD로 생성\n",
    "- output : `hitCompare` 결과\n",
    "\n",
    "**task**\n",
    "\n",
    "`hitCompare(task)` 함수는 다음의 기능을 담고 있습니다.\n",
    "\n",
    "- 1. ``map``을 사용하여 타자 이름 - key / tuple(타수, 안타(1,2,3루타)) - value의 RDD로 transformation 합니다**(regular, pre 각각 생성)** (5 point)\n",
    "\n",
    " **단, value(tuple)의 타입은 float이 되도록 합니다. 또한, 타수 또는 안타 항목이 ''(공백)인 경우 0으로 처리합니다.  [참고](https://niceman.tistory.com/165)** \n",
    "```\n",
    "[('가르시아', (183.0, 62.0)), ('강경학', (1.0, 0.0)), ('강경학', (86.0, 19.0)), ('강경학', (311.0, 80.0)), ...]\n",
    "```\n",
    "\n",
    "- 2. ``reduceByKey와 map``을 이용하여 **역대 정규시즌 평균 타율과 역대 시범경기 평균 타율을 구하여 RDD로 각각 transformation 합니다.** (5 point)\n",
    "\n",
    " **단, 타율 = (안타/타수)  공식을 적용할 것**\n",
    " \n",
    " ```\n",
    " [('가르시아', 0.33879781420765026),\n",
    " ('강구성', 0.125),\n",
    " ('백승룡', 0.1642512077294686),\n",
    " ('진갑용', 0.27565814574589853),\n",
    " ('강백호', 0.2903225806451613),\n",
    " ('강병식', 0.23601532567049807),\n",
    " ('강봉규', 0.2621798091411351),\n",
    " ('강승호', 0.24680851063829787),\n",
    " ('강정호', 0.298371335504886),\n",
    " ('고도현', 0.2727272727272727)]\n",
    " ```\n",
    " \n",
    "\n",
    "- 3. task 1과 task 2에서 정제된 RDD(역대 정규시즌, 역대 시범경기)를 선수 이름(key)로 `join` 후 `filter`를 적용하여 **역대 정규시즌 평균 타율이 역대 시범경기 평균 타율보다 높은 선수의 ``이름-key / tuple(역대 정규시즌 평균 타율, 역대 시범경기 평균 타율)-value의 key/value RDD``로 transformation 합니다** (5 point)\n",
    "\n",
    "- 4. task 3에서 생성된 RDD로부터 역대 정규시즌 평균 타율에 ``sortByKey``를 적용하여 상위 10명의 이름을 출력합니다. (5 point)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "`hitCompare(task)`가 다음을 출력하도록 합니다.\n",
    "\n",
    "```\n",
    "[(0.38461538461538464, '장승현'),\n",
    " (0.36363636363636365, '전병우'),\n",
    " (0.33827893175074186, '이정후'),\n",
    " (0.33410538506079906, '박건우'),\n",
    " (0.3333333333333333, '김태진'),\n",
    " (0.33191489361702126, '구자욱'),\n",
    " (0.32515082171832743, '손아섭'),\n",
    " (0.3247439180537772, '김태균'),\n",
    " (0.32383536861148804, '박민우'),\n",
    " (0.3226377517149812, '김현수')]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1PPqiD1aCOMI",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pre = \"./pre.csv\"\n",
    "regular = \"./regular.csv\"\n",
    "\n",
    "RDD_list = []\n",
    "RDD_list.append(sc.textFile(regular))\n",
    "RDD_list.append(sc.textFile(pre))\n",
    "\n",
    "# 여기에 코드를 입력하세요\n",
    "def hitCompare(task):\n",
    "        \n",
    "print(hitCompare(RDD_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGWB3ugToDUr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GFnagB4HoDcd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QEujJw8e10-D"
   },
   "source": [
    "## Exercise 5 - Key/Value RDD 종합 3 (20 point)\n",
    "\n",
    "- - -\n",
    "\n",
    "기존에 진행했던 HW3의 Exercise 3-4 ``Moby Dic``에서 n-grams 찾기와 매우 유사합니다. \n",
    "\n",
    "주어진 데이터(문장)에서 **NLTK를 이용하여 명사를 추출 및 단어의 길이에 따라 가장 많이 발생되는 단어를 찾는 문제**입니다\n",
    "\n",
    "- word(2-length) : ``` 안녕, 남자, 여자, 생각, 친구 ``` 등\n",
    "    \n",
    "- word(3-length) : ```부모님, 어머니, 아버지, 아이돌, 분위기``` 등\n",
    "\n",
    "- word(4-length) : ```고등학교, 스트레스, 남자친구, 여자친구``` 등\n",
    "\n",
    "이번에 사용할 데이터는 Nate 판(https://pann.nate.com/) 에서 10대 이야기``를 **Web crwalling**을 이용하여 30,000개의 글을 수집한 데이터입니다. \n",
    "\n",
    "\n",
    "**데이터 구성**\n",
    "\n",
    "- 제목  작성일시  조회(수)  본문\n",
    "\n",
    "    예시 : ``\"감기때문에 너무무기력함..어떡해ㅠㅠㅠㅠㅠ\t2018.12.03 21:54\t조회21\t당장 다음주가시험인데 하루종일 공부안하고 누워서 폰하고먹고자고 반복임..머리가 깨질듯이아프니까 공부할 마음이 1도없여 증말\"``\n",
    "    \n",
    "    \n",
    "**Task**\n",
    "- 1. !pip 를 이용하여 jpype1, konlpy 모듈 설치합니다. \n",
    "- 2. 다음의 링크를 참조[[konlpy 설명](https://cceeddcc.tistory.com/8), Okt, Hannanum, Kkma 등 1개 선택]하여, **주어진 문장을 명사로 추출하되 한글(모음) 외에 ``숫자, 특수기호, 조회(위의 데이터 구성 참조)`` 를 삭제하는 ``removeFunctuation``을 작성합니다. 즉, 제목과 본문만을 이용함** (10 point)\n",
    "\n",
    "- 3. removeFunctuation을 통해 명사로 변환된 데이터를 **단어의 길이에 따라 RDD를 생성**합니다.(list 이용 추천). **단, 단어의 길이는 2, 3, 4로 한정.** (5 point)\n",
    "\n",
    "- 4. 출력 예시를 참조하여 출력 함수인 **``printOutput를 작성합니다.``** (5 point)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**출력 예시**\n",
    "\n",
    "```\n",
    "============ 10 most frequent word(2-length)\n",
    "\n",
    "RANK\tCOUNT\tWORD\n",
    "1\t7217: \t\"사람\"\n",
    "2\t6180: \t\"진짜\"\n",
    "3\t5858: \t\"팬톡\"\n",
    "4\t5364: \t\"생각\"\n",
    "5\t4388: \t\"친구\"\n",
    "6\t3443: \t\"지금\"\n",
    "7\t3289: \t\"그냥\"\n",
    "8\t2983: \t\"남자\"\n",
    "9\t2715: \t\"여자\"\n",
    "10\t2572: \t\"우리\"\n",
    "\n",
    "============ 10 most frequent word(3-length)\n",
    "\n",
    "RANK\tCOUNT\tWORD\n",
    "1\t993: \t\"갑자기\"\n",
    "2\t949: \t\"한기총\"\n",
    "3\t835: \t\"부모님\"\n",
    "4\t827: \t\"이야기\"\n",
    "5\t810: \t\"피해자\"\n",
    "6\t714: \t\"신천지\"\n",
    "7\t641: \t\"제페토\"\n",
    "8\t586: \t\"얼마나\"\n",
    "9\t576: \t\"아이돌\"\n",
    "10\t562: \t\"분위기\"\n",
    "\n",
    "============ 10 most frequent word(4-length)\n",
    "\n",
    "RANK\tCOUNT\tWORD\n",
    "1\t860: \t\"남자친구\"\n",
    "2\t671: \t\"고등학교\"\n",
    "3\t456: \t\"여자친구\"\n",
    "4\t443: \t\"스트레스\"\n",
    "5\t281: \t\"대한민국\"\n",
    "6\t253: \t\"다이어트\"\n",
    "7\t251: \t\"우리나라\"\n",
    "8\t195: \t\"트와이스\"\n",
    "9\t194: \t\"시어머니\"\n",
    "10\t163: \t\"미세먼지\"\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bNgnakrd10-H",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pip를 통한 konlpy module 설치\n",
    "!pip install jpype1\n",
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1CBaeTxW10-L",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Nate webcrawling data 30,000 row(page)\n",
    "\n",
    "import urllib.request\n",
    "import re\n",
    "from konlpy.tag import Okt # 한국어 NLP\n",
    "\n",
    "f = urllib.request.urlretrieve (\"https://docs.google.com/uc?export=download&id=1qUQ1GhvkZURUYa_SZI53KrLl1gw6j3VK\", \"Ex4_data.txt\")\n",
    "data_file = \"./Ex4_data.txt\"\n",
    "\n",
    "# 여기에 코드를 입력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-EILnPmoCFO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m0B1o7I3oCMq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-YjpwSjWlk_"
   },
   "source": [
    "## Exercise 6 - Key/Value RDD 종합 4 (20 point)\n",
    "- - -\n",
    "\n",
    "Exercise 4에서 사용했던 데이터를 다시 활용합니다.\n",
    "\n",
    "- word(2-length) : ``` 안녕, 남자, 여자, 생각, 친구 ``` 등\n",
    "    \n",
    "- word(3-length) : ```부모님, 어머니, 아버지, 아이돌, 분위기``` 등\n",
    "    \n",
    "    \n",
    "**Task**\n",
    "- 1. count가 계산된 정제된 word(2-length), word(3-length)에서 **count가 100이상**인 word를 각각의 RDD(RDD1, RDD2)로 생성합니다 **(tip. filter)** (5 point)\n",
    "- 2. input을 RDD list(RDD1과 RDD2가 포함된)로 받고, RDD_list를 join(inner) & 중복제거 후, word를 return 하는 **joinWordPrint**를 작성합니다.**(tip. flatMap, distinct)** (10 point)\n",
    "- 3. 추출된 10개의 word를 이용하여 자신만의 문장을 만듭니다 (5 point)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**출력 예시**\n",
    "- 1. joinWordPrint를 사용하여 추출된 word 출력\n",
    "\n",
    "    ```['남녀', '아파트', '집착', '학기', '걔네', '상관', '그림', '시청', '미래', '펜션']```\n",
    "    \n",
    "    \n",
    "- 2. 나만의 문장 생성(예시 문장) 반드시 **! 선택된 단어는 [ ] 마킹할 것**\n",
    "\n",
    "    ``` 우리 집에는 [쿠션]이 [남아]돈다. 누나가 [매번] 남자친구를 만나고 돌아올 때마다 [쿠션]을 가져온다. 오늘도 어김없이 누나는 왼쪽 겨드랑이에 [쿠션]을 끼고 [등장]하였다. 이번에는 [쿠션] 브랜드 중 [브랜드]의 [쿠션]이라는데.. [길이]가 내 키만큼 길다. 갑자기 누나는 남자친구를 만나야 한다며 짐만 내팽개치고 밖으로 나갔다.. 밤 10시인데.. 뭐가 있나보다.. 나는 알 수 없다.. [매번] 밤 10시에 나간 누나는 다음날 오후 2시가 돼서야 들어온다.. 뭘 하는지 참.. 누나 방 침대는 최근에 구매해서 등과 허리를 아주 편하게 해줘서 sleep 하기 아주 좋은 [환경]이다. 그래서 나는 매번 누나가 남자친구를 야심한 시간에 만나러 갈 때마다, 그곳은 나의 구역이다. 사람은 무언가를 때릴 때 스트레스가 해소가 된다고 한다. 원래 나는 '한 놈만 팬다'의 좌우명을 가지고 있었지만, 오늘은 모든 [쿠션]을 [차별]없이 모두 손봐주었다. 스트레스가 풀린다.. 갑자기 누나가 집으로 왔다. 이번엔 혼자가 아니다. \"[방해]하지 말고.. [가라].. 5천원 줄테니..\". 나는 나의 방으로 돌아왔다. -끝- ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLWhDi-sesY4"
   },
   "outputs": [],
   "source": [
    "def joinWordPrint(word_list):\n",
    "    # 여기에 코드를 입력하세요\n",
    "    \n",
    "    # 이 부분은 upload에 포함할 것\n",
    "    return return_word.takeSample(False, 10) # takseSample이 궁금하다면, google에 검색해볼 것.!\n",
    "\n",
    "print(joinWordPrint(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wD8B0lH5WllD"
   },
   "source": [
    "* 나만의 문장 작성\n",
    ": 여기에 작성하세요"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW4_upload_V1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
