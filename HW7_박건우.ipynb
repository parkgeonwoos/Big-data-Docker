{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2VUCcpqmv7Y"
   },
   "source": [
    "# DataFrame 마무리 & Covariance Matrix(1)\n",
    "- - -\n",
    "\n",
    "#### 1. Performing a `Map` command in DataFrame\n",
    "* In order to perform a map on a dataframe, you first need to transform it into an RDD!\n",
    "* Not the recommended way. Better to use built-in sparkSQL functions\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 2. Covariance Matrix\n",
    "\n",
    "* Calculating the mean of Sample Vectors\n",
    "\n",
    "* Outer product of sample vectors\n",
    "\n",
    "* Covariance Matrix\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zi0a3IDGWkc_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYVwZ8pCmv7a"
   },
   "source": [
    "### 1. Performing a `Map` command in DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMUkFBYmmv7b"
   },
   "source": [
    "#### pyspark import & SparkContext 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rey9WZEmv7b",
    "outputId": "d4d5f2c3-872c-4efe-f617-128c557c75f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[*] appName=pyspark-shell>\n",
      "<pyspark.sql.context.SQLContext object at 0x7fa4400e1ac8>\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import Row, StructField, StructType, StringType, IntegerType\n",
    "\n",
    "sc = SparkContext(master=\"local[*]\")\n",
    "print(sc)\n",
    "\n",
    "# Just like using Spark requires having a SparkContext, using SQL requires an SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "print(sqlContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sI4sev3LWnRX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GoogleDriveDownloader in /opt/conda/lib/python3.7/site-packages (0.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install GoogleDriveDownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aI2e3ctxmv7e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1hAHV6vC6FvVgrYnoN-lR-IfH488-H121 into ./NY.tgz... Done.\n",
      "NY.parquet/\n",
      "NY.parquet/_SUCCESS\n",
      "NY.parquet/part-00022-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00000-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00021-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00001-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00023-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00002-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00024-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00003-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00025-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00004-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00027-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00005-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00006-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00007-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00008-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00009-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00010-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00011-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00012-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00013-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00014-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00015-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00016-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00017-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00018-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00019-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00020-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n",
      "NY.parquet/part-00026-89caf7c0-9733-40ec-a650-7f368529dd01-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "#### 예제 파일 다운로드\n",
    "from os.path import exists\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "import tarfile\n",
    "\n",
    "if exists(\"./NY.tgz\"):\n",
    "    !rm -rf ./NY.tgz\n",
    "if exists(\"./NY.parquet\"):\n",
    "    !rm -rf ./NY.parquet\n",
    "    \n",
    "gdd.download_file_from_google_drive(file_id='1hAHV6vC6FvVgrYnoN-lR-IfH488-H121',\n",
    "                                   dest_path = './NY.tgz')\n",
    "!tar -xzvf NY.tgz\n",
    "df = sqlContext.read.load(\"NY.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UUNu1g5Tmv7f",
    "outputId": "0cb953c2-9f95-4951-f4f6-e00b731f0013",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Station: string (nullable = true)\n",
      " |-- Measurement: string (nullable = true)\n",
      " |-- Year: long (nullable = true)\n",
      " |-- Values: binary (nullable = true)\n",
      " |-- dist_coast: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- elevation: double (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "+-----------+-----------+----+--------------------+------------------+-----------------+------------------+------------------+-----+-----------------+\n",
      "|    Station|Measurement|Year|              Values|        dist_coast|         latitude|         longitude|         elevation|state|             name|\n",
      "+-----------+-----------+----+--------------------+------------------+-----------------+------------------+------------------+-----+-----------------+\n",
      "|USW00014743|   TMIN_s20|1944|[D6 D7 D6 D7 D5 D...| 388.9079895019531|44.57720184326172|-75.10970306396484|136.60000610351562|   NY|      CANTON 4 SE|\n",
      "|USC00307659|   PRCP_s20|1940|[53 4C 54 4C 52 4...|213.64700317382812|42.79999923706055| -74.5999984741211|249.89999389648438|   NY|SHARON SPRINGS 1N|\n",
      "|USC00309055|   SNWD_s20|1991|[14 55 43 55 72 5...| 416.2019958496094|44.35639953613281|-75.92859649658203|  86.9000015258789|   NY| WELLESLEY ISLAND|\n",
      "+-----------+-----------+----+--------------------+------------------+-----------------+------------------+------------------+-----+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printSchema()와 sample를 이용한 데이터 확인\n",
    "df.printSchema()\n",
    "# sample 사용법 참조\n",
    "# https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.sample\n",
    "df.sample(False, 0.01).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kodkuAVSmv7h"
   },
   "source": [
    "* DataFrame to RDD : `[DataFrame].rdd`, 각각의 요소가 `Row`인 RDD 생성\n",
    "\n",
    "* RDD to DataFrame : `sqlContext.createDataFrame([RDD], schema)`\n",
    "\n",
    "단, RDD에서 DataFrame으로 변환시, schema를 꼭 정의해줘야 한다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GAcp0FCmv7h",
    "outputId": "c35586f2-9ba1-4f7e-808c-02c86a15a7cb",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Station='USC00308058', Measurement='TMIN_s20', Year=1963, Values=bytearray(b'\\x06\\xd7\\x1e\\xd76\\xd7N\\xd7d\\xd7y\\xd7\\x91\\xd7\\xaa\\xd7\\xc0\\xd7\\xd6\\xd7\\xec\\xd7\\x01\\xd8\\x0b\\xd8\\x14\\xd8\\x1d\\xd8&\\xd8/\\xd87\\xd8?\\xd8G\\xd8O\\xd8U\\xd8\\\\\\xd8b\\xd8h\\xd8m\\xd8p\\xd8t\\xd8v\\xd8x\\xd8y\\xd8y\\xd8x\\xd8v\\xd8s\\xd8p\\xd8l\\xd8h\\xd8c\\xd8]\\xd8U\\xd8M\\xd8D\\xd89\\xd8/\\xd8%\\xd8\\x19\\xd8\\r\\xd8\\xff\\xd7\\xe3\\xd7\\xc5\\xd7\\xa6\\xd7\\x86\\xd7f\\xd7F\\xd7#\\xd7\\xff\\xd6\\xd9\\xd6\\xb3\\xd6\\x8c\\xd6d\\xd6;\\xd6\\x12\\xd6\\xe8\\xd5\\xbc\\xd5\\x90\\xd5c\\xd56\\xd5\\n\\xd5\\xdd\\xd4\\xb2\\xd4\\x86\\xd4Y\\xd4-\\xd4\\xfd\\xd3\\xa4\\xd3M\\xd3\\xf5\\xd2\\x9e\\xd2H\\xd2\\xf5\\xd1\\xa6\\xd1V\\xd1\\x07\\xd1\\xb9\\xd0m\\xd0$\\xd0\\xba\\xcf0\\xcf\\xa4\\xce\\x18\\xce\\x93\\xcd\\x19\\xcd\\xa0\\xcc)\\xccg\\xcb~\\xca\\x92\\xc9\\xa2\\xc8\\x95\\xc7\\xfd\\xc5f\\xc4y\\xc1;\\xbc\\xdf8S@oCdE\\x02GOH\\x15I\\xd8I\\x8eJ>K\\xf7KXL\\xb3L\\x14MvM\\xd7M?N\\xa4N\\x02OgO\\xccO\\x19PLP\\x81P\\xb7P\\xeeP%Q]Q\\x96Q\\xcdQ\\x00R6RkR\\xa1R\\xd9R\\rSCSxS\\xacS\\xdfS\\nT&TAT[TwT\\x91T\\xabT\\xc4T\\xddT\\xf6T\\x0eU&U=UTUjU\\x80U\\x95U\\xa9U\\xbeU\\xd3U\\xe7U\\xfcU\\x0fV\"V5VGVXViV{V\\x8cV\\x9bV\\xaaV\\xbaV\\xc9V\\xd7V\\xe4V\\xf2V\\x00W\\x0fW\\x1dW*W5WAWLWUW_WiWqWyW\\x80W\\x87W\\x8dW\\x92W\\x95W\\x97W\\x97W\\x98W\\x98W\\x96W\\x94W\\x90W\\x8aW\\x82WyWoWeWYWMWAW2W#W\\x11W\\xffV\\xedV\\xd9V\\xc5V\\xb0V\\x9bV\\x86VpVZVDV,V\\x12V\\xf9U\\xe0U\\xc5U\\xabU\\x91UwU]UCU)U\\x10U\\xf6T\\xddT\\xc6T\\xadT\\x95T|TdTLT5T\\x1fT\\tT\\xe7S\\xbcS\\x91SgS=S\\x16S\\xeeR\\xc6R\\xa0R|RXR7R\\x1aR\\xfdQ\\xe1Q\\xc5Q\\xa9Q\\x8eQuQ]QGQ2Q!Q\\x10Q\\xffP\\xeeP\\xdfP\\xd2P\\xc5P\\xb6P\\xa7P\\x99P\\x8eP\\x82PtPePUPGP8P\\'P\\x15P\\x02P\\xe1O\\xbaO\\x8eO_O-O\\xf8N\\xbdN\\x7fN9N\\xeeM\\xa3MQM\\xf9L\\x9aL4L\\xa2K\\xdbJ\\x0bJ$I7H{FnDa@/\\xa9\\xb7\\xc0\\xa3\\xc4\\x03\\xc7\\xb6\\xc8\\xf8\\xc9>\\xcbG\\xcc\\xf7\\xcc\\xa3\\xcdV\\xce\\x0f\\xcf\\xca\\xcfA\\xd0\\x9f\\xd0\\xfe\\xd0]\\xd1\\xba\\xd1\\x16\\xd2s\\xd2\\xd0\\xd2)\\xd3\\x82\\xd3\\xd9\\xd3\\x17\\xd4?\\xd4i\\xd4\\x92\\xd4\\xba\\xd4\\xe1\\xd4\\x07\\xd5*\\xd5J\\xd5j\\xd5\\x8a\\xd5\\xa7\\xd5\\xc3\\xd5\\xdc\\xd5\\xf1\\xd5\\x06\\xd6\\x19\\xd6-\\xd6>\\xd6M\\xd6Z\\xd6d\\xd6n\\xd6w\\xd6~\\xd6\\x86\\xd6\\x8b\\xd6'), dist_coast=410.5090026855469, latitude=42.71670150756836, longitude=-78.5999984741211, elevation=331.8999938964844, state='NY', name='SOUTH WALES EMERY PARK')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_rdd = df.rdd.takeSample(False, 1)\n",
    "some_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RC9wok3kmv7j"
   },
   "source": [
    "* Lec 6의 예제\n",
    "\n",
    "    1. 주어진 DataFrame에서 `Year가 1900 미만인 경우 '19th'`, `2000 미만인 경우 '20th'`, `2010 미만인 경우 '21st'`, `모두 아닐 경우 'possibly_bad_data'로 값을 치환`하여라\n",
    "\n",
    " 여기서 `map`에 들어가는 `input`이 무엇인지 반드시 숙지하여야 한다.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSSFoeotmv7k",
    "outputId": "f2713cb4-283f-47fd-a597-5c859bfb5a74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20th', '20th', '20th', '20th', '20th']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_century(row):\n",
    "    if row.Year < 1900:\n",
    "        return \"19th\"\n",
    "    elif row.Year < 2000:\n",
    "        return \"20th\"\n",
    "    elif row.Year < 2010:\n",
    "        return \"21st\"\n",
    "    else:\n",
    "        return \"possibly_bad_data\"\n",
    "    \n",
    "df.rdd.map(find_century).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TzFXzrhmmv7l"
   },
   "source": [
    "* Lec 6의 예제\n",
    "\n",
    "    2. 주어진 DataFrame에서 각각의 요소 중 `longitude`와 `latitude`를 추출하여 (longitude, latitude)의 형태로 값을 출력하여라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q2KNPUc0mv7m",
    "outputId": "7aa18389-8ca7-4356-bcca-9848b2433dee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-77.71330261230469, 42.57080078125),\n",
       " (-77.71330261230469, 42.57080078125),\n",
       " (-77.71330261230469, 42.57080078125),\n",
       " (-77.71330261230469, 42.57080078125),\n",
       " (-77.71330261230469, 42.57080078125)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.map(lambda row : (row.longitude, row.latitude)).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAz482zDmv7n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1OuM3jhrmv7p"
   },
   "source": [
    "### Excercise 1 - RDD function in DataFrame (60 point)\n",
    "\n",
    "- - -\n",
    "task 별로 ``위에서 사용한 DataFrame(df)``에서 ``RDD``로 변환 후 ``RDD function``을 적용하여 해결합니다\n",
    "\n",
    "(task 당 20 point)\n",
    "\n",
    "---\n",
    "\n",
    "**task**\n",
    "\n",
    "* 1 : ``df``에서 ``name``별 가장 최근 ``Year``를 **map과 reduce, 또는 reduceByKey 등**을 활용하여 구한 후, take(10)을 통하여 출력합니다.(20 point)\n",
    "\n",
    "<br>\n",
    "\n",
    "* 2 : ``df``에서 ``Year``가 ``2000 이상``인 결과에 대해, ``name``별 ``Year``, ``dist_coast``, ``elevation``의 평균을 구하고 ``name``를 기준으로 정렬(Z->A)한 후, take(5)을 통하여 출력합니다.(20 point)\n",
    "\n",
    "<br>\n",
    "\n",
    "* 3 : ``df``에서 ``Measurement`` 별 `Values`의 1일부터 10일까지(``np.frombuffer(row.Values[:20], dtype='float16')`` 또는 ``np.frombuffer(row.Values, dtype = 'float16')[:10])의 합이 가장 큰 ``Year``와 ``그 값을 구한 후``, ``Measurement``를 기준으로 정렬(A->Z)합니다. 마지막으로 collect를 하여 출력합니다.(20 point) \n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iNu7gzmpmv7p"
   },
   "source": [
    "**task**\n",
    "\n",
    "* 1 : ``df``에서 ``name``별 가장 최근 ``Year``를 **map과 reduce, 또는 reduceByKey 등**을 활용하여 구한 후, take(10)을 통하여 출력합니다.(20 point)\n",
    "\n",
    "**★ DataFrame이 아닌 RDD로 작업할 것**\n",
    "\n",
    "```\n",
    "#task1 output\n",
    "[('DANSVILLE MUNI AP', 2013),\n",
    " ('BRIDGEHAMPTON', 2013),\n",
    " ('MIDDLETOWN 2 NW', 2011),\n",
    " ('BERLIN 5 S', 2000),\n",
    " ('ELMIRA CORNING RGNL AP', 2013),\n",
    " ('UNADILLA 2 N', 2013),\n",
    " ('SUFFERN 2 E', 1955),\n",
    " ('ROXBURY', 1972),\n",
    " ('LOWVILLE', 2013),\n",
    " ('GABRIELS', 1978)]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5Qtu4q6mv7p",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SABATTIS WHITNEY PARK', 1958),\n",
       " ('RAY BROOK', 2004),\n",
       " ('SHARON SPRINGS 1N', 1953),\n",
       " ('MIDDLETOWN 2 NW', 2011),\n",
       " ('BERLIN 5 S', 2000),\n",
       " ('ELMIRA CORNING RGNL AP', 2013),\n",
       " ('WALTON', 1997),\n",
       " ('GRAFTON', 2004),\n",
       " ('WALDEN 1 ESE', 2012),\n",
       " ('GARNERVILLE', 1989)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-1 답 작성  \n",
    "df.rdd.map(lambda row:(row.name,row.Year)).reduceByKey(lambda x,y:x if x>y else y).take(10)#df에서 rdd로 변환해주는데 row의name열과 year만 뽑아서 가져오고 그 후에 키 값을 묶고 value가 긴 값을 뽑아냄\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2xTPOidmv7r"
   },
   "source": [
    "**task**\n",
    "\n",
    "* 2 : ``df``에서 ``Year``가 ``2000 이상``인 결과에 대해, ``name``별 ``Year``, ``dist_coast``, ``elevation``의 평균을 구하고 ``name``를 기준으로 정렬(Z->A)한 후, take(10)을 통하여 출력합니다.(20 point)\n",
    "\n",
    "**★ DataFrame이 아닌 RDD로 작업할 것**\n",
    "\n",
    "```\n",
    "# task2 output\n",
    "[('YOUNGSTOWN 2 NE', (2008.5, 476.80999755859375, 85.30000305175781)),\n",
    " ('YORKTOWN HEIGHTS 1W',\n",
    "  (2006.421686746988, 28.945999145507812, 204.1999969482422)),\n",
    " ('WINDHAM 3 E', (2004.8387096774193, 147.28700256347656, 512.0999755859375)),\n",
    " ('WILLSBORO 1 N',\n",
    "  (2005.360655737705, 255.24200439453125, 54.900001525878906)),\n",
    " ('WHITNEY POINT DAM', (2009.2826086956522, 235.35800170898438, 317.0))]\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "a=(1,2)\n",
    "b=(2,3)\n",
    "print(a[0]/b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-nU-RqQmv7r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RAY BROOK',\n",
       "  (2001.8148148148148, 16392.617248535156, 54, 493.79998779296875)),\n",
       " ('MIDDLETOWN 2 NW', (2005.5, 11675.332397460938, 144, 213.39999389648438)),\n",
       " ('BERLIN 5 S', (2000.0, 904.9979553222656, 6, 347.5)),\n",
       " ('ELMIRA CORNING RGNL AP',\n",
       "  (2005.78, 28038.198852539062, 100, 291.1000061035156)),\n",
       " ('GRAFTON', (2002.0, 10232.279663085938, 60, 475.5)),\n",
       " ('WALDEN 1 ESE', (2006.0, 11223.918640136719, 156, 115.80000305175781)),\n",
       " ('TRENTON FALLS',\n",
       "  (2007.4705882352941, 28717.793701171875, 102, 243.8000030517578)),\n",
       " ('PAVILION',\n",
       "  (2008.2631578947369, 46388.310974121094, 114, 291.3999938964844)),\n",
       " ('MASSENA INTL AP',\n",
       "  (2006.7291666666667, 33609.791015625, 96, 65.19999694824219)),\n",
       " ('LIBERTY 1 NE', (2006.0, 20039.603942871094, 156, 481.6000061035156))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-2 답 작성  \n",
    "a=df.rdd.map(lambda row:(row.name,(row.Year,row.dist_coast,row.elevation,1))).filter(lambda x:(x[1][0])>=2000).reduceByKey(lambda x,y:(x[0]+y[0],x[1]+y[1],x[2]+y[2],x[3]+y[3]))\n",
    "a.map(lambda row:(row[0],(row[1][0]/row[1][3],row[1][1],row[1][3],row[1][2]/row[1][3]))).take(10)\n",
    "#a에 df을 rdd형태로 바꿔주고 row형식으로 나타내는데 row는 key,value RDD형태로 만들어주는데 key는 row.name,value는 row.year,row.dist_coast,row.elevtion,1로 만들어주고 row.year이 2000년 이상으로 조건을 걸어주고  reduceByKey를 통해 ,x와 y의  각 자리의 값을 더해줌\n",
    "#a를 매핑해서 나온 결과를 나눠서 원하는 값을 얻고 10개만 값을 봄\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CjP5V4xymv7w"
   },
   "source": [
    "**task**\n",
    "\n",
    "* 3 : ``df``에서 ``Measurement`` 별 `Values`의 1일부터 10일까지(``np.frombuffer(row.Values[:20], dtype='float16')`` 또는 ``np.frombuffer(row.Values, dtype = 'float16')[:10])의 합이 가장 큰 ``Year``와 ``그 값을 구한 후``, ``Measurement``를 기준으로 정렬(A->Z)합니다. 마지막으로 collect를 하여 출력합니다.(20 point) \n",
    "\n",
    "<br>\n",
    "\n",
    "**★ DataFrame이 아닌 RDD로 작업할 것**\n",
    "\n",
    "★★여기서 ``Values``는 ``bytearray`` type입니다. ★★\n",
    "\n",
    "``numpy``의 **frombuffer**를 이용하여 ``float16``으로 바꿉니다.\n",
    "자세한 사용법은 [여기](https://docs.scipy.org/doc/numpy/reference/generated/numpy.frombuffer.html)를 참고합니다\n",
    "\n",
    "★★또한, ``numpy``의 ``nansum``을 이용하여 값이 **nan**이 아닌 Values의 합을 구합니다.★★\n",
    "\n",
    "```\n",
    "# task3 output\n",
    "[('PRCP', (12824.0, 1946)),\n",
    " ('PRCP_s20', (4264.0, 1983)),\n",
    " ('SNOW', (2912.0, 1954)),\n",
    " ('SNOW_s20', (4140.0, 1895)),\n",
    " ('SNWD', (16590.0, 1970)),\n",
    " ('SNWD_s20', (12320.0, 1976)),\n",
    " ('TMAX', (2216.0, 1897)),\n",
    " ('TMAX_s20', (2050.0, 1897)),\n",
    " ('TMIN', (623.0, 2007)),\n",
    " ('TMIN_s20', (21360.0, 1987)),\n",
    " ('TOBS', (1000.0, 1998)),\n",
    " ('TOBS_s20', (969.5, 1992))]\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PRCP', (12824.0, 1946)),\n",
       " ('TMAX', (2216.0, 1897)),\n",
       " ('TOBS', (1000.0, 1998)),\n",
       " ('SNWD_s20', (12320.0, 1976)),\n",
       " ('SNOW_s20', (4140.0, 1895)),\n",
       " ('PRCP_s20', (4264.0, 1983)),\n",
       " ('TOBS_s20', (969.5, 1992)),\n",
       " ('TMIN_s20', (21360.0, 1987)),\n",
       " ('TMIN', (623.0, 2007)),\n",
       " ('TMAX_s20', (2050.0, 1897)),\n",
       " ('SNOW', (2912.0, 1954)),\n",
       " ('SNWD', (16590.0, 1970))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=df.rdd.map(lambda row:(row.Measurement,(np.nansum(np.frombuffer(row.Values, dtype = 'float16')[:10]),row.Year))).reduceByKey(lambda x,y:x if x[0]>y[0] else y)\n",
    "a.collect()\n",
    "#a는 rdd형태로 만들고 map을 통해서 row를 만들어주는데 key는 Measurement로 하고 nansum함수를 이용하여 row.values를 dtype='float16'으로 바꾼후 10까지 더하고뒤에 row.year을 넣어서 row를 마무리 후 rreduceyke를 통해 x[0]와y[0] 합의 값을 비교 후 큰 것을 산출\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wBSUHVbmv7w"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:37259)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:37259)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-46d3c841ad06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeasurement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f, preservesPartitioning)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfail_on_stopiteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitionsWithIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreservesPartitioning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflatMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreservesPartitioning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mmapPartitionsWithIndex\u001b[0;34m(self, f, preservesPartitioning)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \"\"\"\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPipelinedRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreservesPartitioning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmapPartitionsWithSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreservesPartitioning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, prev, func, preservesPartitioning, isFromBarrier)\u001b[0m\n\u001b[1;32m   2512\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bypass_serializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitioner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitioner\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreservesPartitioning\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2514\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_barrier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_barrier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misFromBarrier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2516\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetNumPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_is_barrier\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2412\u001b[0m         \u001b[0mWhether\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mRDD\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mbarrier\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2413\u001b[0m         \"\"\"\n\u001b[0;32m-> 2414\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misBarrier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    981\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \"\"\"\n\u001b[0;32m--> 983\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    936\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:37259)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=df.rdd.map(lambda row:(row.Measurement,np.nansum(np.frombuffer(row.Values, dtype = 'float16')[:10])))\n",
    "a.collect()                                                                                                          \n",
    "\n",
    "\n",
    "# 1-3 답 작성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7An8T1Nq2ltD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0Z5dZeD2ltF"
   },
   "source": [
    "### 2. Spark와 Numpy를 사용하여 Covariance Matrix 구해보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yt_7LRtgBY_a"
   },
   "source": [
    "#### (1) numpy 기초 \n",
    "아래 참고자료를 활용하여 numpy 기초 학습\n",
    "\n",
    "* 참고자료 \n",
    "  * [참고자료 1](http://taewan.kim/post/numpy_cheat_sheet/)\n",
    "  * [참고자료 2](https://docs.scipy.org/doc/numpy/user/quickstart.html)\n",
    "  * [참고자료 3](https://scipy-lectures.org/intro/numpy/array_object.html#what-are-numpy-and-numpy-arrays)\n",
    "  * [참고자료 4](https://doorbw.tistory.com/171)\n",
    "  * [참고자료 5](https://datascienceschool.net/view-notebook/17608f897087478bbeac096438c716f6/)\n",
    "\n",
    "* 위 자료에서중에서도 \n",
    "  * ndarray 생성법\n",
    "  * vector, matrix 연산\n",
    "  * 인덱싱 (slicing)\n",
    "  * 행렬 합치기 (vstack, dstack, hstack)\n",
    "  * sum, mean\n",
    "  * np.nan 자료형\n",
    "  * reshape\n",
    "  * matmul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g9N7GWN5m0aj"
   },
   "source": [
    "#### (2)  Calculating the mean of Sample Vectors \n",
    "다음 벡터들을 샘플 벡터로 가정합니다.\n",
    "* $n$ 은 샘플의 수 이고\n",
    "* $d$는 각 데이터 벡터의 길이 입니다 (예를 들어서 날씨데이터의 경우 $d=365$)\n",
    "$$\n",
    "\\mathbf{x}_i = \\left[\\begin{array}{cccc}\n",
    "x_{i1} & x_{i2}& \\ldots & x_{id}, \n",
    "\\end{array}\\right], \\quad i=1,\\ldots, n\n",
    "$$\n",
    "Sample vector 들의 mean (평균) 벡터 $\\bar{\\mathbf{x}}$는 다음과 같이 구합니다 \n",
    "$$\n",
    "\\bar{\\mathbf{x}} = \\frac{1}{n}\\sum_{i=1}^n \\mathbf{x}_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yl5QnvQZ4yvX"
   },
   "outputs": [],
   "source": [
    "# 평균 벡터 구하는 문제 (sum, mean 활용 둘다 해도 괜찮습니다))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELHX1CFB2ltL",
    "outputId": "4e7c71c5-3d6c-4c7e-99dd-c5837af7b920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 sample의 값 :  [1 2 3] [4 5 6] [7 8 9]\n",
      "sample vector sum :  [12 15 18]\n",
      "sample vector mean :  [4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "# in python\n",
    "import numpy as np\n",
    "\n",
    "sample1 = np.array([1,2,3])\n",
    "sample2 = np.array([4,5,6])\n",
    "sample3 = np.array([7,8,9])\n",
    "print(\"각 sample의 값 : \", sample1, sample2, sample3)\n",
    "print(\"sample vector sum : \", sample1 + sample2 + sample3)\n",
    "print(\"sample vector mean : \", (sample1 + sample2 + sample3) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMYlw8JX9f7u",
    "outputId": "0be9a8c8-9ba1-462b-fc10-ef3b58a89d60",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 sample의 값 :  [array([1, 2, 3]), array([4, 5, 6]), array([7, 8, 9])]\n",
      "sample vector sum :  [12 15 18]\n",
      "sample vector mean :  [4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "# in spark\n",
    "vector_list = sc.parallelize([np.array([1,2,3]),np.array([4,5,6]),np.array([7,8,9])])\n",
    "print(\"각 sample의 값 : \", vector_list.collect())\n",
    "print(\"sample vector sum : \", vector_list.reduce(lambda ndarr1, ndarr2 : ndarr1 + ndarr2))\n",
    "print(\"sample vector mean : \",\n",
    "      vector_list.reduce(lambda ndarr1, ndarr2 : ndarr1 + ndarr2) / vector_list.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6vVD-9dp2ltR"
   },
   "source": [
    "### Excercise 2 - Calculating the mean of Sample Vectors (40 point)\n",
    "\n",
    "- - -\n",
    " \n",
    "다음 데이터에 대하여 다음 과제를 수행하세요.\n",
    "\n",
    "- regular.csv : KBO에서 활약한 타자들의 역대 정규시즌 성적을 포함하여 몸무게, 키 ,생년월일 등의 기본정보\n",
    "\n",
    "**위의 두 데이터는 모두 `,`로 구분되어 있습니다.**\n",
    "\n",
    " - **데이터의 자세한 설명은 다음의 링크를 참조해주세요.([여기를 눌러서 12. 데이터 설명 참고](https://dacon.io/cpt6/62885))**\n",
    " - 또한 regular.csv를 직접 열어서 데이터가 어떻게 저장되어 있는지 확인해주세요.\n",
    "\n",
    "- - -\n",
    "\n",
    "**task**\n",
    "\n",
    "- 1. filter를 사용하여 팀 이름이 ``두산``인 선수에 대해, ``(batter_id, np.array([G,R,H,RBI,BB]))``의 형태로 Key/Value RDD를 생성합니다. (20 point)\n",
    "\n",
    "    1. G R H RBI BB의 경우 초기 설정값이 ``stirng``.  이 값들을 ``float64``으로 변경할 것. ex) ``np.array([1,2,3], dtype = 'float64')``\n",
    "    2. ★ 각 값이 `' '`일 경우, 0 으로 변경할 것. \n",
    "    3. ``map``에서 바로 적용 또는 그러한 함수를 작성\n",
    "    \n",
    "\n",
    "<br>\n",
    "\n",
    "- 2. (20 point)\n",
    "    1. ``reduceByKey``를 사용하여 ``batter_id``(Key)가 동일한 선수의 ``G, R, H, RBI, BB``(Value)를 각각 더해준 후 ``batter_id``(Key)를 기준으로 ``sortByKey``를 적용합니다. 그 후, ``map``을 사용하여 ``G, R, H, RBI, BB``(Value)만 선택 후 새로운 RDD로 만듭니다.\n",
    "    2. 위에서 생성된 RDD에 대해, 중복되지 않는 sample의 수를 ``count``를 이용하여 구합니다.\n",
    "    3. ``reduce``를 이용하여 ``G, R, H, RBI, BB``(Value)를 모두 더한 후 위에서 구한 sample의 수(`count`)로 나누어서 sample vector의 평균을 구합니다.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sE2zQXh92ltS"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "f = urllib.request.urlretrieve (\"https://docs.google.com/uc?export=download&id=1b_L-rJYJC9Oqga0fQ2zh2M763CTM8jzR\", \"regular.csv\")\n",
    "regular = sc.textFile(\"./regular.csv\").map(lambda x : x.split(\",\")) #RDD 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsNIE2482ltW"
   },
   "source": [
    "**task**\n",
    "\n",
    "- 1. filter를 사용하여 팀 이름이 ``두산``인 선수에 대해, ``(batter_id, np.array([G,R,H,RBI,BB]))``의 형태로 Key/Value RDD를 생성합니다. (20 point)\n",
    "\n",
    "    1. G R H RBI BB의 경우 초기 설정값이 ``stirng``.  이 값들을 ``float64``으로 변경할 것. ex) ``np.array([1,2,3], dtype = 'float64')``\n",
    "    2. ★ 각 값이 `' '`일 경우, 0 으로 변경할 것. \n",
    "    3. ``map``에서 바로 적용 또는 그러한 함수를 작성\n",
    "    \n",
    "```\n",
    "#output\n",
    "[(7, array([1., 0., 0., 0., 0.])),\n",
    " (7, array([64., 16., 21., 11.,  6.])),\n",
    " (7, array([93., 30., 40., 25., 16.])),\n",
    " (7, array([6., 3., 3., 3., 2.])),\n",
    " (7, array([40., 14., 17.,  5., 10.])),\n",
    " (7, array([48., 12., 24., 10., 18.])),\n",
    " (17, array([16.,  1.,  1.,  1.,  0.])),\n",
    " (17, array([32.,  2.,  3.,  0.,  0.])),\n",
    " (17, array([16.,  2.,  2.,  0.,  0.])),\n",
    " (17, array([116.,  38.,  85.,  29.,  24.]))]\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7', array([1., 0., 0., 0., 0.])),\n",
       " ('7', array([64., 16., 21., 11.,  6.])),\n",
       " ('7', array([93., 30., 40., 25., 16.])),\n",
       " ('7', array([6., 3., 3., 3., 2.])),\n",
       " ('7', array([40., 14., 17.,  5., 10.])),\n",
       " ('7', array([48., 12., 24., 10., 18.])),\n",
       " ('17', array([16.,  1.,  1.,  1.,  0.])),\n",
       " ('17', array([32.,  2.,  3.,  0.,  0.])),\n",
       " ('17', array([16.,  2.,  2.,  0.,  0.])),\n",
       " ('17', array([116.,  38.,  85.,  29.,  24.])),\n",
       " ('17', array([126.,  89., 119.,  66.,  61.])),\n",
       " ('17', array([126.,  84., 114.,  70.,  74.])),\n",
       " ('17', array([85., 59., 66., 29., 33.])),\n",
       " ('17', array([100.,  53.,  60.,  35.,  34.])),\n",
       " ('17', array([93., 31., 37., 16., 18.])),\n",
       " ('17', array([58., 33., 40., 26., 13.])),\n",
       " ('17', array([10.,  3.,  4.,  1.,  3.])),\n",
       " ('17', array([52., 18., 27.,  7., 11.])),\n",
       " ('17', array([41., 13., 22., 11.,  6.])),\n",
       " ('17', array([8., 1., 1., 1., 1.])),\n",
       " ('20', array([3., 0., 0., 0., 0.])),\n",
       " ('20', array([11.,  6.,  4.,  5.,  2.])),\n",
       " ('20', array([58., 28., 42., 24., 21.])),\n",
       " ('20', array([57., 15., 18., 17.,  5.])),\n",
       " ('20', array([14.,  4.,  8.,  1.,  3.])),\n",
       " ('32', array([114.,  62., 128.,  84.,  41.])),\n",
       " ('32', array([127.,  78., 159., 106.,  51.])),\n",
       " ('32', array([103.,  49., 118.,  62.,  47.])),\n",
       " ('32', array([120.,  63., 132.,  79.,  52.])),\n",
       " ('32', array([118.,  61., 137.,  89.,  79.])),\n",
       " ('32', array([124.,  72., 123.,  76.,  69.])),\n",
       " ('32', array([94., 51., 81., 50., 57.])),\n",
       " ('32', array([43., 19., 35., 16., 23.])),\n",
       " ('32', array([119.,  68., 123.,  78.,  83.])),\n",
       " ('32', array([109.,  55., 112., 104.,  63.])),\n",
       " ('32', array([105.,  63., 125.,  86.,  61.])),\n",
       " ('32', array([110.,  60., 114.,  67.,  67.])),\n",
       " ('32', array([120.,  57., 116.,  75.,  66.])),\n",
       " ('32', array([66., 18., 65., 27., 16.])),\n",
       " ('32', array([28.,  6., 21.,  9., 10.])),\n",
       " ('33', array([10.,  3.,  3.,  0.,  0.])),\n",
       " ('33', array([26.,  9.,  7.,  4.,  2.])),\n",
       " ('50', array([38., 12.,  6.,  2.,  5.])),\n",
       " ('51', array([11.,  0.,  2.,  3.,  0.])),\n",
       " ('51', array([4., 1., 1., 2., 0.])),\n",
       " ('52', array([14.,  0.,  3.,  3.,  1.])),\n",
       " ('52', array([31.,  5.,  8.,  4.,  1.])),\n",
       " ('52', array([46., 16., 25., 10., 12.])),\n",
       " ('57', array([36.,  4.,  0.,  0.,  0.])),\n",
       " ('57', array([47.,  6.,  6.,  4.,  2.])),\n",
       " ('57', array([112.,  48.,  65.,  21.,  25.])),\n",
       " ('57', array([80., 27., 43., 36., 20.])),\n",
       " ('57', array([83., 11., 19.,  8., 14.])),\n",
       " ('57', array([57.,  6., 20.,  9.,  7.])),\n",
       " ('57', array([84., 23., 38., 11., 16.])),\n",
       " ('57', array([91., 42., 78., 32., 26.])),\n",
       " ('57', array([122.,  50.,  86.,  54.,  54.])),\n",
       " ('57', array([133.,  63., 126.,  50.,  54.])),\n",
       " ('57', array([137.,  69., 129.,  78.,  57.])),\n",
       " ('57', array([91., 34., 83., 50., 36.])),\n",
       " ('57', array([131.,  78., 125.,  75.,  52.])),\n",
       " ('58', array([14.,  0.,  3.,  0.,  0.])),\n",
       " ('58', array([30.,  4., 10.,  8.,  1.])),\n",
       " ('58', array([13.,  7.,  5.,  1.,  4.])),\n",
       " ('58', array([52., 12., 26., 13., 11.])),\n",
       " ('58', array([48., 24., 36., 22., 22.])),\n",
       " ('58', array([134., 107., 160., 124.,  71.])),\n",
       " ('58', array([144., 110., 185., 115.,  81.])),\n",
       " ('58', array([139., 104., 176., 133.,  59.])),\n",
       " ('73', array([1., 0., 0., 0., 0.])),\n",
       " ('73', array([99., 33., 87., 32., 26.])),\n",
       " ('73', array([126.,  83., 168.,  89.,  80.])),\n",
       " ('73', array([133.,  97., 172., 104.,  80.])),\n",
       " ('73', array([132.,  88., 150.,  89.,  78.])),\n",
       " ('73', array([130.,  71., 143.,  91.,  71.])),\n",
       " ('73', array([122.,  47., 127.,  65.,  46.])),\n",
       " ('73', array([122.,  63., 131.,  90.,  62.])),\n",
       " ('73', array([125.,  75., 149.,  90.,  53.])),\n",
       " ('73', array([141., 103., 167., 121., 101.])),\n",
       " ('83', array([96., 21., 15.,  3., 12.])),\n",
       " ('83', array([64., 14., 18.,  9.,  3.])),\n",
       " ('83', array([99., 21., 47., 19., 10.])),\n",
       " ('83', array([114.,  20.,  54.,  30.,  18.])),\n",
       " ('92', array([76., 30., 67., 50., 29.])),\n",
       " ('96', array([2., 0., 1., 0., 0.])),\n",
       " ('96', array([14.,  3.,  1.,  0.,  0.])),\n",
       " ('96', array([90., 34., 34.,  9., 10.])),\n",
       " ('96', array([125.,  60.,  77.,  26.,  21.])),\n",
       " ('96', array([128.,  52.,  61.,  29.,  29.])),\n",
       " ('103', array([80., 20., 12.,  4.,  2.])),\n",
       " ('103', array([119.,  53.,  80.,  31.,  28.])),\n",
       " ('103', array([87., 26., 18.,  0.,  6.])),\n",
       " ('103', array([115.,  49.,  67.,  28.,  17.])),\n",
       " ('103', array([64., 23., 20.,  4.,  9.])),\n",
       " ('103', array([2., 0., 1., 0., 0.])),\n",
       " ('103', array([119.,  71., 122.,  65.,  40.])),\n",
       " ('103', array([124.,  85., 162.,  79.,  37.])),\n",
       " ('103', array([129.,  80., 149.,  75.,  50.])),\n",
       " ('103', array([134.,  98., 166.,  87.,  48.])),\n",
       " ('103', array([123.,  73., 136.,  71.,  47.])),\n",
       " ('104', array([5., 1., 1., 0., 0.])),\n",
       " ('104', array([34., 12., 13.,  7.,  1.])),\n",
       " ('104', array([47.,  7., 11.,  3.,  4.])),\n",
       " ('104', array([70., 31., 54., 26., 12.])),\n",
       " ('104', array([132.,  95., 162.,  83.,  38.])),\n",
       " ('104', array([131.,  91., 177.,  78.,  41.])),\n",
       " ('104', array([125.,  79., 159.,  84.,  28.])),\n",
       " ('116', array([6., 1., 2., 1., 0.])),\n",
       " ('116', array([18.,  4.,  6.,  2.,  3.])),\n",
       " ('116', array([87., 26., 36., 23., 22.])),\n",
       " ('116', array([97., 41., 57., 26., 19.])),\n",
       " ('116', array([89., 37., 48., 22., 16.])),\n",
       " ('120', array([3., 0., 1., 0., 0.])),\n",
       " ('136', array([23.,  7.,  6.,  4.,  5.])),\n",
       " ('148', array([59., 16., 31.,  6.,  6.])),\n",
       " ('148', array([122.,  45.,  80.,  39.,  30.])),\n",
       " ('148', array([126.,  59., 115.,  60.,  48.])),\n",
       " ('148', array([126.,  29., 108.,  34.,  35.])),\n",
       " ('148', array([121.,  56., 119.,  59.,  42.])),\n",
       " ('148', array([128.,  51., 118.,  62.,  46.])),\n",
       " ('148', array([92., 39., 84., 28., 37.])),\n",
       " ('148', array([86., 24., 67., 31., 21.])),\n",
       " ('148', array([93., 35., 59., 26., 21.])),\n",
       " ('162', array([34.,  5., 11.,  7.,  2.])),\n",
       " ('162', array([16.,  5.,  4.,  2.,  2.])),\n",
       " ('174', array([3., 0., 0., 0., 0.])),\n",
       " ('174', array([127.,  48., 100.,  68.,  40.])),\n",
       " ('174', array([119.,  43., 113.,  46.,  44.])),\n",
       " ('174', array([122.,  39., 100.,  27.,  37.])),\n",
       " ('174', array([114.,  37.,  77.,  57.,  36.])),\n",
       " ('174', array([97., 40., 87., 46., 24.])),\n",
       " ('174', array([132.,  70., 144.,  93.,  39.])),\n",
       " ('174', array([108.,  66., 106.,  66.,  40.])),\n",
       " ('174', array([111.,  47.,  96.,  67.,  43.])),\n",
       " ('174', array([133.,  84., 157.,  77.,  45.])),\n",
       " ('175', array([5., 0., 0., 0., 0.])),\n",
       " ('175', array([32.,  6.,  2.,  2.,  2.])),\n",
       " ('175', array([21.,  5.,  4.,  1.,  1.])),\n",
       " ('179', array([49., 10., 15.,  5.,  4.])),\n",
       " ('179', array([117.,  45.,  70.,  28.,  17.])),\n",
       " ('179', array([106.,  36.,  48.,  12.,  20.])),\n",
       " ('179', array([123.,  59., 106.,  37.,  29.])),\n",
       " ('179', array([129.,  73., 129.,  46.,  39.])),\n",
       " ('179', array([77., 29., 53., 17., 17.])),\n",
       " ('179', array([113.,  54.,  80.,  44.,  49.])),\n",
       " ('179', array([110.,  60., 114.,  40.,  50.])),\n",
       " ('179', array([120.,  60., 115.,  59.,  47.])),\n",
       " ('179', array([122.,  68., 113.,  58.,  54.])),\n",
       " ('179', array([127.,  43.,  79.,  40.,  47.])),\n",
       " ('179', array([132.,  78., 148.,  81.,  41.])),\n",
       " ('180', array([87., 16., 43., 25., 10.])),\n",
       " ('180', array([55., 16., 35., 28., 20.])),\n",
       " ('180', array([75., 10., 32., 18., 20.])),\n",
       " ('180', array([66., 33., 52., 36., 28.])),\n",
       " ('180', array([105.,  69., 120.,  92.,  64.])),\n",
       " ('180', array([128.,  62., 126.,  89.,  45.])),\n",
       " ('180', array([123.,  69., 112.,  80.,  60.])),\n",
       " ('185', array([5., 1., 2., 1., 0.])),\n",
       " ('185', array([59., 13., 31., 10., 10.])),\n",
       " ('185', array([58.,  9., 18.,  6.,  5.])),\n",
       " ('185', array([79., 17., 48., 14., 11.])),\n",
       " ('185', array([43.,  7.,  6.,  0.,  3.])),\n",
       " ('185', array([60.,  3.,  7.,  2.,  0.])),\n",
       " ('188', array([15.,  5., 10.,  6.,  5.])),\n",
       " ('194', array([3., 1., 0., 0., 0.])),\n",
       " ('194', array([1., 0., 0., 0., 0.])),\n",
       " ('194', array([27.,  3.,  8.,  3.,  3.])),\n",
       " ('194', array([30.,  1.,  2.,  0.,  1.])),\n",
       " ('194', array([80., 18., 48., 19., 17.])),\n",
       " ('194', array([109.,  25.,  84.,  48.,  18.])),\n",
       " ('194', array([21., 12., 20.,  8.,  4.])),\n",
       " ('200', array([109.,  33.,  78.,  36.,  29.])),\n",
       " ('200', array([90., 22., 60., 23., 16.])),\n",
       " ('200', array([38.,  5., 16.,  7.,  3.])),\n",
       " ('208', array([28.,  5.,  6.,  2.,  1.])),\n",
       " ('210', array([4., 1., 2., 0., 0.])),\n",
       " ('210', array([4., 1., 1., 0., 0.])),\n",
       " ('211', array([84., 23., 47., 29., 26.])),\n",
       " ('211', array([31.,  7., 17.,  5.,  7.])),\n",
       " ('211', array([129.,  77., 110.,  86.,  40.])),\n",
       " ('211', array([83., 23., 56., 28., 16.])),\n",
       " ('219', array([2., 0., 1., 0., 0.])),\n",
       " ('219', array([2., 0., 0., 0., 0.])),\n",
       " ('220', array([125.,  49., 112.,  53.,  28.])),\n",
       " ('220', array([104.,  36.,  78.,  49.,  26.])),\n",
       " ('220', array([110.,  36.,  57.,  35.,  29.])),\n",
       " ('220', array([107.,  36.,  87.,  42.,  30.])),\n",
       " ('220', array([85., 40., 83., 39., 29.])),\n",
       " ('220', array([79., 29., 58., 25., 19.])),\n",
       " ('220', array([7., 3., 6., 7., 2.])),\n",
       " ('229', array([120.,  76., 110.,  32.,  40.])),\n",
       " ('229', array([123.,  84., 147.,  46.,  48.])),\n",
       " ('229', array([122.,  98., 138.,  28.,  52.])),\n",
       " ('229', array([82., 48., 86., 28., 28.])),\n",
       " ('229', array([114.,  66., 129.,  45.,  45.])),\n",
       " ('229', array([121.,  64., 132.,  44.,  49.])),\n",
       " ('229', array([121.,  57., 105.,  39.,  43.])),\n",
       " ('229', array([110.,  77., 123.,  52.,  38.])),\n",
       " ('245', array([7., 0., 0., 0., 0.])),\n",
       " ('248', array([51., 13., 18.,  5.,  6.])),\n",
       " ('248', array([109.,  41., 104.,  30.,  35.])),\n",
       " ('248', array([99., 37., 72., 20., 24.])),\n",
       " ('248', array([121.,  61., 101.,  50.,  52.])),\n",
       " ('248', array([96., 27., 38., 18., 31.])),\n",
       " ('248', array([36., 20., 27., 10., 16.])),\n",
       " ('248', array([66., 16., 33., 14.,  8.])),\n",
       " ('248', array([70., 19., 29., 10., 27.])),\n",
       " ('251', array([45., 16., 14.,  8.,  3.])),\n",
       " ('251', array([53., 15., 10.,  4.,  7.])),\n",
       " ('254', array([20.,  2.,  5.,  1.,  1.])),\n",
       " ('259', array([12.,  2.,  3.,  3.,  0.])),\n",
       " ('271', array([85., 47., 61., 17., 24.])),\n",
       " ('271', array([76., 35., 46., 19., 10.])),\n",
       " ('271', array([128.,  66., 118.,  38.,  40.])),\n",
       " ('271', array([101.,  46.,  74.,  32.,  18.])),\n",
       " ('271', array([125.,  57.,  63.,  29.,  16.])),\n",
       " ('271', array([128.,  79., 132.,  49.,  41.])),\n",
       " ('271', array([128.,  79., 145.,  59.,  43.])),\n",
       " ('271', array([114.,  49.,  65.,  20.,  25.])),\n",
       " ('271', array([26., 20., 36., 23., 11.])),\n",
       " ('278', array([47.,  7.,  4.,  3.,  2.])),\n",
       " ('278', array([46., 14., 17.,  5.,  6.])),\n",
       " ('278', array([77., 37., 36., 18., 14.])),\n",
       " ('278', array([31.,  9.,  9.,  3.,  6.])),\n",
       " ('278', array([97., 43., 56., 31., 19.])),\n",
       " ('278', array([111.,  53.,  81.,  37.,  19.])),\n",
       " ('286', array([66., 16.,  8.,  3.,  0.])),\n",
       " ('286', array([80., 17., 13.,  2.,  4.])),\n",
       " ('286', array([119.,  35.,  51.,  17.,   9.])),\n",
       " ('299', array([15.,  0.,  3.,  2.,  3.])),\n",
       " ('299', array([91., 32., 66., 30., 10.])),\n",
       " ('299', array([112.,  33.,  73.,  42.,  13.])),\n",
       " ('308', array([4., 1., 1., 1., 0.])),\n",
       " ('308', array([1., 0., 0., 0., 0.])),\n",
       " ('312', array([1., 0., 0., 0., 0.])),\n",
       " ('312', array([69.,  9., 19.,  8.,  4.])),\n",
       " ('312', array([60., 12., 24.,  8.,  6.])),\n",
       " ('312', array([48.,  9., 27., 10.,  5.])),\n",
       " ('312', array([71.,  6., 15.,  7.,  3.])),\n",
       " ('312', array([22.,  1.,  3.,  4.,  2.])),\n",
       " ('315', array([4., 0., 0., 0., 0.])),\n",
       " ('315', array([3., 0., 0., 0., 0.])),\n",
       " ('315', array([16.,  3.,  4.,  6.,  1.])),\n",
       " ('315', array([9., 0., 0., 0., 0.])),\n",
       " ('315', array([81., 29., 57., 22., 18.])),\n",
       " ('315', array([47., 12., 27., 10.,  8.])),\n",
       " ('315', array([82., 38., 53., 31., 14.])),\n",
       " ('315', array([100.,  34.,  67.,  32.,  25.])),\n",
       " ('315', array([85., 21., 45., 22., 12.])),\n",
       " ('315', array([129.,  65., 120.,  57.,  38.])),\n",
       " ('315', array([138.,  87., 173., 108.,  51.])),\n",
       " ('316', array([109.,  28.,  79.,  47.,  34.])),\n",
       " ('316', array([121.,  48.,  94.,  75.,  51.])),\n",
       " ('316', array([67., 16., 38., 23., 23.])),\n",
       " ('316', array([116.,  49., 109.,  94.,  49.])),\n",
       " ('316', array([127.,  63., 136.,  82.,  50.])),\n",
       " ('316', array([124.,  49., 114.,  75.,  56.])),\n",
       " ('316', array([89., 15., 62., 30., 25.])),\n",
       " ('316', array([100.,  22.,  60.,  36.,  39.])),\n",
       " ('321', array([111.,  56., 116.,  72.,  34.])),\n",
       " ('331', array([92., 28., 41., 14.,  7.])),\n",
       " ('331', array([75., 35., 68., 25., 27.])),\n",
       " ('331', array([105.,  33.,  49.,  10.,  21.])),\n",
       " ('331', array([117.,  64., 128.,  41.,  31.])),\n",
       " ('331', array([144.,  96., 154.,  81.,  49.])),\n",
       " ('331', array([130.,  50.,  95.,  40.,  29.])),\n",
       " ('331', array([133.,  85., 167.,  79.,  32.])),\n",
       " ('332', array([1., 0., 0., 0., 0.])),\n",
       " ('336', array([111.,  47.,  91.,  63.,  22.])),\n",
       " ('336', array([127.,  55., 127.,  59.,  32.])),\n",
       " ('336', array([122.,  50., 109.,  48.,  26.])),\n",
       " ('336', array([127.,  51., 125.,  70.,  37.])),\n",
       " ('336', array([73., 20., 70., 36., 15.])),\n",
       " ('336', array([133.,  62., 165.,  86.,  36.])),\n",
       " ('336', array([115.,  41., 107.,  74.,  29.])),\n",
       " ('336', array([119.,  36., 112.,  56.,  26.])),\n",
       " ('336', array([80., 21., 62., 39., 26.])),\n",
       " ('336', array([114.,  45., 140.,  63.,  25.])),\n",
       " ('336', array([127.,  61., 140.,  72.,  57.])),\n",
       " ('336', array([124.,  63., 141.,  82.,  64.])),\n",
       " ('336', array([93., 39., 79., 46., 42.])),\n",
       " ('336', array([17.,  4., 10.,  5.,  5.]))]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=regular.filter(lambda x:x[3]=='두산').map(lambda x:(x[0],np.frombuffer(np.array([x[5],x[7],x[8],x[13],x[16]],dtype='float64'))))\n",
    "a.collect()\n",
    "#regular가 rdd형태이므로 filter를 통해 두산인 선수만 거르고 map을 통해 x[0]인 batter_id를 key값 value값에는 주어진 조건에 넣고 dtyper을 float64fh 바꾼후 출력\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WVX2WOiY2lte"
   },
   "source": [
    "**task**\n",
    "\n",
    "- 2. (20 point)\n",
    "    1. ``reduceByKey``를 사용하여 ``batter_id``(Key)가 동일한 선수의 ``G, R, H, RBI, BB``(Value)를 각각 더해준 후 ``batter_id``(Key)를 기준으로 ``sortByKey``를 적용합니다. 그 후, ``map``을 사용하여 ``G, R, H, RBI, BB``(Value)만 선택 후 새로운 RDD로 만듭니다.\n",
    "    2. 위에서 생성된 RDD에 대해, 중복되지 않는 sample의 수를 ``count``를 이용하여 구합니다.\n",
    "    3. ``reduce``를 이용하여 ``G, R, H, RBI, BB``(Value)를 모두 더한 후 위에서 구한 sample의 수(`count`)로 나누어서 sample vector의 평균을 구합니다.\n",
    "\n",
    "```\n",
    "# output\n",
    "[G, R, H, RBI, BB] mean :  [427.8846  186.32692 344.05768 178.0577  129.48077]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reduce'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-6cf0d13ef153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reduce'"
     ]
    }
   ],
   "source": [
    "a=1,2]\n",
    "b=(2,3)\n",
    "a.reduce(lambda x:x*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LVvi_9gy2ltg",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[G, R, H, RBI, BB] mean :  (1143.6386834319528, 538.2910502958581, 789.4400887573967, 398.0329142011835, 356.64201183431965)\n"
     ]
    }
   ],
   "source": [
    "a=regular.filter(lambda x:x[3]=='두산').map(lambda x:(x[0],np.frombuffer(np.array([x[5],x[7],x[8],x[13],x[16]],dtype='float64')))).reduceByKey(lambda x,y:(x[0]+y[0],x[1]+y[1],x[2]+y[2],x[3]+y[3],x[4]+y[4]))\n",
    "#regular가 rdd형태이므로 filter를 통해 두산인 선수만 거르고 map을 통해 x[0]인 batter_id를 key값 value값에는 주어진 조건에 넣고 dtyper을 float64fh 바꾼후 출력후 reduceByKey를 통해 원소의 각 값을 더해줌\n",
    "a.sortByKey()\n",
    "#나온 값을 정렬\n",
    "b=a.map(lambda x:(x[1][0],x[1][1],x[1][2],x[1][3],x[1][4]))#뒤의 g,r,h,rbi,bb등의 원소만 rdd로 출력\n",
    "c=b.count()#원소의 갯수를 카운트하여 c에 저장\n",
    "task2_mean_vector=b.reduce(lambda x,y:((x[0]+y[0]/c),(x[1]+y[1]/c),(x[2]+y[2]/c),(x[3]+y[3]/c),(x[4]+y[4]/c)))\n",
    "# task2_mean_vector에 b를 reduce 하여 g,r,h,rbi,bb의 값을 더하고 count로 나눈 후 저장\n",
    "\n",
    "#b는 원소의 값만을 rdd로만 뽑아냄\n",
    "#b.collect()\n",
    "#output\n",
    "print(\"[G, R, H, RBI, BB] mean : \", task2_mean_vector) #결과를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "43q9xB_nvllT"
   },
   "source": [
    "# 기말고사가 다가온다.ㅋ"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW7_upload_V4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
